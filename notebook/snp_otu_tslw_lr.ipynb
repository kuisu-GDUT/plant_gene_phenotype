{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor, plot_importance, plot_tree\n",
    "import xgboost as xgb\n",
    "from scipy.stats import t\n",
    "import statsmodels.api as sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "otu_path = r\"D:\\05_kuisu\\project\\15_MAI\\Foxtail-millet-data-analysis\\Figure2\\OTU0.7.csv\"\n",
    "tslw_snp_path = r\"D:\\05_kuisu\\project\\15_MAI\\Foxtail-millet-data-analysis\\Figure2\\TSLWSNP.csv\"\n",
    "\n",
    "df_otu = pd.read_csv(otu_path)\n",
    "df_snp = pd.read_csv(tslw_snp_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   sample  OTU_97  OTU_17917  OTU_164  OTU_110  OTU_28612  OTU_42  OTU_281  \\\n0  Si_102  3.4726     1.4241   1.4241   1.9282     1.4241  2.8425  1.42410   \n1  Si_105  3.7887     1.7997   1.1639   3.2757     5.0735  3.1469  1.61720   \n2  Si_106  3.2836     2.1369   1.9681   2.6644     3.2836  3.4207  0.97884   \n3  Si_108  4.1436     2.9225   2.4297   2.8365     4.9466  2.9225  0.90887   \n4  Si_109  3.3673     1.9244   1.2618   3.4310     3.5506  2.7207  0.95007   \n\n   OTU_28306  OTU_192  ...       PC1       PC2       PC3       PC4       PC5  \\\n0     5.1616   1.9282  ... -0.042467  0.012649 -0.008380  0.021947 -0.012261   \n1     5.2247   2.2394  ...  0.022155 -0.005878  0.003327 -0.003975  0.032975   \n2     5.6724   2.6644  ... -0.036409 -0.007399 -0.009371 -0.020853  0.002437   \n3     5.4595   3.5274  ...  0.022437 -0.009861  0.005828 -0.003640  0.010850   \n4     4.7600   1.9244  ...  0.037184 -0.007725  0.008184  0.021918  0.023928   \n\n        PC6       PC7       PC8       PC9      PC10  \n0 -0.020675 -0.058306  0.013853  0.022379 -0.039418  \n1 -0.080775  0.008381  0.093369  0.053368  0.076554  \n2 -0.014775 -0.022514  0.016131 -0.010219 -0.000622  \n3 -0.035365 -0.002141  0.017251  0.001907  0.031235  \n4 -0.047812  0.005075  0.053935  0.017500  0.025807  \n\n[5 rows x 1024 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>OTU_97</th>\n      <th>OTU_17917</th>\n      <th>OTU_164</th>\n      <th>OTU_110</th>\n      <th>OTU_28612</th>\n      <th>OTU_42</th>\n      <th>OTU_281</th>\n      <th>OTU_28306</th>\n      <th>OTU_192</th>\n      <th>...</th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Si_102</td>\n      <td>3.4726</td>\n      <td>1.4241</td>\n      <td>1.4241</td>\n      <td>1.9282</td>\n      <td>1.4241</td>\n      <td>2.8425</td>\n      <td>1.42410</td>\n      <td>5.1616</td>\n      <td>1.9282</td>\n      <td>...</td>\n      <td>-0.042467</td>\n      <td>0.012649</td>\n      <td>-0.008380</td>\n      <td>0.021947</td>\n      <td>-0.012261</td>\n      <td>-0.020675</td>\n      <td>-0.058306</td>\n      <td>0.013853</td>\n      <td>0.022379</td>\n      <td>-0.039418</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Si_105</td>\n      <td>3.7887</td>\n      <td>1.7997</td>\n      <td>1.1639</td>\n      <td>3.2757</td>\n      <td>5.0735</td>\n      <td>3.1469</td>\n      <td>1.61720</td>\n      <td>5.2247</td>\n      <td>2.2394</td>\n      <td>...</td>\n      <td>0.022155</td>\n      <td>-0.005878</td>\n      <td>0.003327</td>\n      <td>-0.003975</td>\n      <td>0.032975</td>\n      <td>-0.080775</td>\n      <td>0.008381</td>\n      <td>0.093369</td>\n      <td>0.053368</td>\n      <td>0.076554</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Si_106</td>\n      <td>3.2836</td>\n      <td>2.1369</td>\n      <td>1.9681</td>\n      <td>2.6644</td>\n      <td>3.2836</td>\n      <td>3.4207</td>\n      <td>0.97884</td>\n      <td>5.6724</td>\n      <td>2.6644</td>\n      <td>...</td>\n      <td>-0.036409</td>\n      <td>-0.007399</td>\n      <td>-0.009371</td>\n      <td>-0.020853</td>\n      <td>0.002437</td>\n      <td>-0.014775</td>\n      <td>-0.022514</td>\n      <td>0.016131</td>\n      <td>-0.010219</td>\n      <td>-0.000622</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Si_108</td>\n      <td>4.1436</td>\n      <td>2.9225</td>\n      <td>2.4297</td>\n      <td>2.8365</td>\n      <td>4.9466</td>\n      <td>2.9225</td>\n      <td>0.90887</td>\n      <td>5.4595</td>\n      <td>3.5274</td>\n      <td>...</td>\n      <td>0.022437</td>\n      <td>-0.009861</td>\n      <td>0.005828</td>\n      <td>-0.003640</td>\n      <td>0.010850</td>\n      <td>-0.035365</td>\n      <td>-0.002141</td>\n      <td>0.017251</td>\n      <td>0.001907</td>\n      <td>0.031235</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Si_109</td>\n      <td>3.3673</td>\n      <td>1.9244</td>\n      <td>1.2618</td>\n      <td>3.4310</td>\n      <td>3.5506</td>\n      <td>2.7207</td>\n      <td>0.95007</td>\n      <td>4.7600</td>\n      <td>1.9244</td>\n      <td>...</td>\n      <td>0.037184</td>\n      <td>-0.007725</td>\n      <td>0.008184</td>\n      <td>0.021918</td>\n      <td>0.023928</td>\n      <td>-0.047812</td>\n      <td>0.005075</td>\n      <td>0.053935</td>\n      <td>0.017500</td>\n      <td>0.025807</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1024 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_otu.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   sample  snp1  snp2  snp3  snp4  snp5  snp6  snp7  snp8  snp9\n0  Si_102   0.0   2.0   0.0   0.0   0.0   0.0   2.0   0.0   2.0\n1  Si_105   2.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0\n2  Si_106   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0\n3  Si_108   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0\n4  Si_109   0.0   NaN   0.0   0.0   0.0   0.0   0.0   0.0   2.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>snp1</th>\n      <th>snp2</th>\n      <th>snp3</th>\n      <th>snp4</th>\n      <th>snp5</th>\n      <th>snp6</th>\n      <th>snp7</th>\n      <th>snp8</th>\n      <th>snp9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Si_102</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Si_105</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Si_106</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Si_108</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Si_109</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snp.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   sample   MSPD  OTU_97  OTU_17917  OTU_164  OTU_110  OTU_28612  OTU_42  \\\n0  Si_102   3.62  3.4726     1.4241   1.4241   1.9282     1.4241  2.8425   \n1  Si_105  31.30  3.7887     1.7997   1.1639   3.2757     5.0735  3.1469   \n2  Si_106  33.43  3.2836     2.1369   1.9681   2.6644     3.2836  3.4207   \n3  Si_108  31.57  4.1436     2.9225   2.4297   2.8365     4.9466  2.9225   \n4  Si_109  33.40  3.3673     1.9244   1.2618   3.4310     3.5506  2.7207   \n\n   OTU_281  OTU_28306  ...      PC10  snp1  snp2  snp3  snp4  snp5  snp6  \\\n0  1.42410     5.1616  ... -0.039418   0.0   2.0   0.0   0.0   0.0   0.0   \n1  1.61720     5.2247  ...  0.076554   2.0   0.0   0.0   0.0   0.0   2.0   \n2  0.97884     5.6724  ... -0.000622   0.0   2.0   0.0   0.0   0.0   0.0   \n3  0.90887     5.4595  ...  0.031235   0.0   0.0   0.0   0.0   0.0   2.0   \n4  0.95007     4.7600  ...  0.025807   0.0   NaN   0.0   0.0   0.0   0.0   \n\n   snp7  snp8  snp9  \n0   2.0   0.0   2.0  \n1   0.0   0.0   0.0  \n2   0.0   0.0   2.0  \n3   0.0   0.0   0.0  \n4   0.0   0.0   2.0  \n\n[5 rows x 1025 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>MSPD</th>\n      <th>OTU_97</th>\n      <th>OTU_17917</th>\n      <th>OTU_164</th>\n      <th>OTU_110</th>\n      <th>OTU_28612</th>\n      <th>OTU_42</th>\n      <th>OTU_281</th>\n      <th>OTU_28306</th>\n      <th>...</th>\n      <th>PC10</th>\n      <th>snp1</th>\n      <th>snp2</th>\n      <th>snp3</th>\n      <th>snp4</th>\n      <th>snp5</th>\n      <th>snp6</th>\n      <th>snp7</th>\n      <th>snp8</th>\n      <th>snp9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Si_102</td>\n      <td>3.62</td>\n      <td>3.4726</td>\n      <td>1.4241</td>\n      <td>1.4241</td>\n      <td>1.9282</td>\n      <td>1.4241</td>\n      <td>2.8425</td>\n      <td>1.42410</td>\n      <td>5.1616</td>\n      <td>...</td>\n      <td>-0.039418</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Si_105</td>\n      <td>31.30</td>\n      <td>3.7887</td>\n      <td>1.7997</td>\n      <td>1.1639</td>\n      <td>3.2757</td>\n      <td>5.0735</td>\n      <td>3.1469</td>\n      <td>1.61720</td>\n      <td>5.2247</td>\n      <td>...</td>\n      <td>0.076554</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Si_106</td>\n      <td>33.43</td>\n      <td>3.2836</td>\n      <td>2.1369</td>\n      <td>1.9681</td>\n      <td>2.6644</td>\n      <td>3.2836</td>\n      <td>3.4207</td>\n      <td>0.97884</td>\n      <td>5.6724</td>\n      <td>...</td>\n      <td>-0.000622</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Si_108</td>\n      <td>31.57</td>\n      <td>4.1436</td>\n      <td>2.9225</td>\n      <td>2.4297</td>\n      <td>2.8365</td>\n      <td>4.9466</td>\n      <td>2.9225</td>\n      <td>0.90887</td>\n      <td>5.4595</td>\n      <td>...</td>\n      <td>0.031235</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Si_109</td>\n      <td>33.40</td>\n      <td>3.3673</td>\n      <td>1.9244</td>\n      <td>1.2618</td>\n      <td>3.4310</td>\n      <td>3.5506</td>\n      <td>2.7207</td>\n      <td>0.95007</td>\n      <td>4.7600</td>\n      <td>...</td>\n      <td>0.025807</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1025 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tslw_idx = [0, 1007]\n",
    "tslw_idx.extend([i for i in range(1, 1005)])\n",
    "tslw_idx.extend([i for i in range(1014, 1024)])\n",
    "df_tslw = pd.merge(df_otu.iloc[:, tslw_idx], df_snp, on=\"sample\")\n",
    "df_tslw.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680, 1025)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   sample   MSPD  OTU_97  OTU_17917  OTU_164  OTU_110  OTU_28612  OTU_42  \\\n0  Si_102   3.62  3.4726     1.4241   1.4241   1.9282     1.4241  2.8425   \n1  Si_105  31.30  3.7887     1.7997   1.1639   3.2757     5.0735  3.1469   \n2  Si_106  33.43  3.2836     2.1369   1.9681   2.6644     3.2836  3.4207   \n3  Si_108  31.57  4.1436     2.9225   2.4297   2.8365     4.9466  2.9225   \n5  Si_113  28.63  2.7158     1.0091   1.0091   2.4743     3.1861  3.1035   \n\n   OTU_281  OTU_28306  ...      PC10  snp1  snp2  snp3  snp4  snp5  snp6  \\\n0  1.42410     5.1616  ... -0.039418   0.0   2.0   0.0   0.0   0.0   0.0   \n1  1.61720     5.2247  ...  0.076554   2.0   0.0   0.0   0.0   0.0   2.0   \n2  0.97884     5.6724  ... -0.000622   0.0   2.0   0.0   0.0   0.0   0.0   \n3  0.90887     5.4595  ...  0.031235   0.0   0.0   0.0   0.0   0.0   2.0   \n5  1.59710     4.9002  ...  0.015700   0.0   0.0   0.0   0.0   0.0   2.0   \n\n   snp7  snp8  snp9  \n0   2.0   0.0   2.0  \n1   0.0   0.0   0.0  \n2   0.0   0.0   2.0  \n3   0.0   0.0   0.0  \n5   0.0   0.0   0.0  \n\n[5 rows x 1025 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>MSPD</th>\n      <th>OTU_97</th>\n      <th>OTU_17917</th>\n      <th>OTU_164</th>\n      <th>OTU_110</th>\n      <th>OTU_28612</th>\n      <th>OTU_42</th>\n      <th>OTU_281</th>\n      <th>OTU_28306</th>\n      <th>...</th>\n      <th>PC10</th>\n      <th>snp1</th>\n      <th>snp2</th>\n      <th>snp3</th>\n      <th>snp4</th>\n      <th>snp5</th>\n      <th>snp6</th>\n      <th>snp7</th>\n      <th>snp8</th>\n      <th>snp9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Si_102</td>\n      <td>3.62</td>\n      <td>3.4726</td>\n      <td>1.4241</td>\n      <td>1.4241</td>\n      <td>1.9282</td>\n      <td>1.4241</td>\n      <td>2.8425</td>\n      <td>1.42410</td>\n      <td>5.1616</td>\n      <td>...</td>\n      <td>-0.039418</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Si_105</td>\n      <td>31.30</td>\n      <td>3.7887</td>\n      <td>1.7997</td>\n      <td>1.1639</td>\n      <td>3.2757</td>\n      <td>5.0735</td>\n      <td>3.1469</td>\n      <td>1.61720</td>\n      <td>5.2247</td>\n      <td>...</td>\n      <td>0.076554</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Si_106</td>\n      <td>33.43</td>\n      <td>3.2836</td>\n      <td>2.1369</td>\n      <td>1.9681</td>\n      <td>2.6644</td>\n      <td>3.2836</td>\n      <td>3.4207</td>\n      <td>0.97884</td>\n      <td>5.6724</td>\n      <td>...</td>\n      <td>-0.000622</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Si_108</td>\n      <td>31.57</td>\n      <td>4.1436</td>\n      <td>2.9225</td>\n      <td>2.4297</td>\n      <td>2.8365</td>\n      <td>4.9466</td>\n      <td>2.9225</td>\n      <td>0.90887</td>\n      <td>5.4595</td>\n      <td>...</td>\n      <td>0.031235</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Si_113</td>\n      <td>28.63</td>\n      <td>2.7158</td>\n      <td>1.0091</td>\n      <td>1.0091</td>\n      <td>2.4743</td>\n      <td>3.1861</td>\n      <td>3.1035</td>\n      <td>1.59710</td>\n      <td>4.9002</td>\n      <td>...</td>\n      <td>0.015700</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1025 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop column with including NaN\n",
    "data = df_tslw.dropna(axis=0, how='any')\n",
    "print(data.shape)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TSLW'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\04_programe\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mD:\\04_programe\\anaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\04_programe\\anaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'TSLW'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# describe label of info\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTSLW\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mdescribe()\n",
      "File \u001B[1;32mD:\\04_programe\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mD:\\04_programe\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'TSLW'"
     ]
    }
   ],
   "source": [
    "# describe label of info\n",
    "data[\"TSLW\"].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "          V1  Estimate  Std.Error             P\n0     OTU_97  0.004898   0.003979  2.188144e-01\n1  OTU_17917  0.007185   0.007702  3.512216e-01\n2    OTU_164 -0.000606   0.007938  9.391253e-01\n3    OTU_110  0.015101   0.004851  1.930226e-03\n4  OTU_28612  0.018342   0.003359  6.677754e-08",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>Estimate</th>\n      <th>Std.Error</th>\n      <th>P</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OTU_97</td>\n      <td>0.004898</td>\n      <td>0.003979</td>\n      <td>2.188144e-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OTU_17917</td>\n      <td>0.007185</td>\n      <td>0.007702</td>\n      <td>3.512216e-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OTU_164</td>\n      <td>-0.000606</td>\n      <td>0.007938</td>\n      <td>9.391253e-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OTU_110</td>\n      <td>0.015101</td>\n      <td>0.004851</td>\n      <td>1.930226e-03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OTU_28612</td>\n      <td>0.018342</td>\n      <td>0.003359</td>\n      <td>6.677754e-08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose OTU features by P Value\n",
    "results = []\n",
    "for i in range(2, 1006):\n",
    "    variable_name = data.columns[i]\n",
    "    X = data.iloc[:, i].values.reshape(-1, 1)\n",
    "    Y = data[\"TSLW\"].values\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, Y)\n",
    "    coef = model.coef_[0]\n",
    "    predictions = model.predict(X)\n",
    "    n = len(X)\n",
    "    mse = np.mean((Y - predictions) ** 2)\n",
    "    std_err = np.sqrt(mse * (np.linalg.inv(np.dot(X.T, X)))[0, 0])\n",
    "    # 计算 t 值\n",
    "    t_val = coef / std_err\n",
    "    # 需要样本数和自由度来计算p值\n",
    "    degrees_of_freedom = n - 2\n",
    "    # 计算p值 (双尾)\n",
    "    p_val = 2 * (1 - t.cdf(abs(t_val), df=degrees_of_freedom))\n",
    "    # 添加结果到列表中\n",
    "    results.append([variable_name, coef, std_err, p_val])\n",
    "r = pd.DataFrame(results, columns=[\"V1\", \"Estimate\", \"Std.Error\", \"P\"])\n",
    "r.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "           V1  Estimate  Std.Error         P\n239  OTU_7084 -0.000032   0.006733  0.996152\n189    OTU_59 -0.000065   0.004496  0.988408\n95    OTU_320  0.000173   0.010584  0.986970\n427   OTU_383  0.000139   0.008467  0.986904\n452  OTU_2690 -0.000175   0.009088  0.984620",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>Estimate</th>\n      <th>Std.Error</th>\n      <th>P</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>239</th>\n      <td>OTU_7084</td>\n      <td>-0.000032</td>\n      <td>0.006733</td>\n      <td>0.996152</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>OTU_59</td>\n      <td>-0.000065</td>\n      <td>0.004496</td>\n      <td>0.988408</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>OTU_320</td>\n      <td>0.000173</td>\n      <td>0.010584</td>\n      <td>0.986970</td>\n    </tr>\n    <tr>\n      <th>427</th>\n      <td>OTU_383</td>\n      <td>0.000139</td>\n      <td>0.008467</td>\n      <td>0.986904</td>\n    </tr>\n    <tr>\n      <th>452</th>\n      <td>OTU_2690</td>\n      <td>-0.000175</td>\n      <td>0.009088</td>\n      <td>0.984620</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 200 feature by P order\n",
    "r_order = r.sort_values(by=[\"P\"], ascending=False)\n",
    "r_order.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc nums: 200\n",
      "snp_columns:9\n",
      "otu_columns:1004\n",
      "pc_columns:10\n",
      "data_0 shape: (136, 1025)\n",
      "data_1 shape: (136, 1025)\n",
      "data_2 shape: (136, 1025)\n",
      "data_3 shape: (136, 1025)\n",
      "data_4 shape: (136, 1025)\n"
     ]
    }
   ],
   "source": [
    "# 获取所有列名为”snp“开头的列\n",
    "cc = list(r_order[\"V1\"][:200].values)  # 相关性较高的top200\n",
    "snp_columns = [col for col in data.columns if re.match(r\"^snp\", col)]\n",
    "otu_columns = [col for col in data.columns if re.match(r\"OTU\", col)]\n",
    "pc_columns = [col for col in data.columns if re.match(r\"^PC\", col)]\n",
    "print(\n",
    "    f\"cc nums: {len(cc)}\\nsnp_columns:{len(snp_columns)}\\notu_columns:{len(otu_columns)}\\npc_columns:{len(pc_columns)}\")\n",
    "# split data to 5 part\n",
    "random_data = data.sample(frac=1)\n",
    "sample_nums = len(random_data)\n",
    "datas = []\n",
    "for i in range(5):\n",
    "    sample = random_data.sample(min(sample_nums // 5, len(random_data)), replace=True)\n",
    "    datas.append(sample)\n",
    "    print(f\"data_{i} shape: {sample.shape}\")\n",
    "\n",
    "\n",
    "# 使用逐步回归（向后逐步回归）\n",
    "def backward_elimination(data, target, significance_level=0.05):\n",
    "    initial_features = data.columns.tolist()\n",
    "    while len(initial_features) > 0:\n",
    "        X = sm.add_constant(data[initial_features])\n",
    "        model = sm.OLS(target, X).fit()\n",
    "        p_values = model.pvalues.iloc[1:]  # 不包括常数项的 p 值\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > significance_level:\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            print(f\"remove feature: {excluded_feature}, p value: {max_p_value}\")\n",
    "            initial_features.remove(excluded_feature)\n",
    "        else:\n",
    "            break\n",
    "    return initial_features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Based on the SNP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (544, 1025)\n",
      "test shape: (136, 1025)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.131\n",
      "Model:                            OLS   Adj. R-squared:                  0.118\n",
      "Method:                 Least Squares   F-statistic:                     10.12\n",
      "Date:                Wed, 15 May 2024   Prob (F-statistic):           3.40e-13\n",
      "Time:                        10:25:51   Log-Likelihood:                -132.33\n",
      "No. Observations:                 544   AIC:                             282.7\n",
      "Df Residuals:                     535   BIC:                             321.3\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.6353      0.453      8.018      0.000       2.745       4.526\n",
      "snp1           0.3374      0.074      4.559      0.000       0.192       0.483\n",
      "snp2          -0.4160      0.225     -1.850      0.065      -0.858       0.026\n",
      "snp3          -0.0654      0.021     -3.077      0.002      -0.107      -0.024\n",
      "snp4           0.0200      0.028      0.716      0.474      -0.035       0.075\n",
      "snp5           0.0200      0.028      0.716      0.474      -0.035       0.075\n",
      "snp6          -0.5148      0.227     -2.270      0.024      -0.960      -0.069\n",
      "snp7          -0.0864      0.028     -3.132      0.002      -0.141      -0.032\n",
      "snp8           0.0991      0.037      2.697      0.007       0.027       0.171\n",
      "snp9           0.0051      0.018      0.289      0.773      -0.030       0.040\n",
      "==============================================================================\n",
      "Omnibus:                        1.937   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.380   Jarque-Bera (JB):                1.904\n",
      "Skew:                          -0.019   Prob(JB):                        0.386\n",
      "Kurtosis:                       3.287   Cond. No.                     4.90e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.73e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# 创建初始线性回归模型\n",
    "train_data = pd.concat([datas[i] for i in [0, 1, 2, 3]], axis=0)\n",
    "test_data = datas[4]\n",
    "print(f\"train data shape: {train_data.shape}\\ntest data shape: {test_data.shape}\")\n",
    "X = train_data[snp_columns]\n",
    "y = train_data[\"TSLW\"]\n",
    "X = sm.add_constant(X)  # 添加常数项\n",
    "TSLWm1 = sm.OLS(y, X).fit()\n",
    "print(TSLWm1.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2 score: 0.1314\n",
      "test r2 score: 0.0489\n",
      "pred:2.616, label:2.800\n",
      "pred:2.606, label:2.800\n",
      "pred:2.606, label:2.900\n",
      "pred:2.683, label:3.070\n",
      "pred:2.804, label:2.930\n",
      "pred:2.814, label:3.200\n",
      "pred:2.606, label:2.630\n",
      "pred:2.606, label:2.730\n",
      "pred:2.606, label:2.730\n",
      "pred:2.606, label:2.330\n",
      "pred:2.606, label:2.670\n",
      "pred:2.803, label:2.970\n",
      "pred:2.475, label:2.100\n",
      "pred:2.814, label:2.630\n",
      "pred:2.631, label:2.770\n",
      "pred:2.803, label:2.600\n",
      "pred:2.606, label:2.730\n",
      "pred:2.803, label:2.700\n",
      "pred:2.606, label:2.570\n",
      "pred:2.606, label:2.170\n",
      "pred:2.727, label:2.800\n",
      "pred:2.606, label:2.500\n",
      "pred:2.803, label:2.170\n",
      "pred:2.727, label:2.570\n",
      "pred:2.606, label:2.500\n",
      "pred:2.606, label:2.600\n",
      "pred:2.814, label:2.800\n",
      "pred:2.606, label:3.100\n",
      "pred:2.814, label:2.800\n",
      "pred:2.475, label:2.500\n",
      "pred:2.641, label:2.770\n",
      "pred:2.683, label:2.600\n",
      "pred:2.814, label:3.000\n",
      "pred:2.814, label:2.770\n",
      "pred:2.606, label:2.200\n",
      "pred:2.606, label:2.630\n",
      "pred:2.606, label:2.730\n",
      "pred:2.606, label:2.600\n",
      "pred:2.606, label:2.900\n",
      "pred:2.606, label:2.300\n",
      "pred:2.814, label:2.300\n",
      "pred:2.616, label:3.000\n",
      "pred:2.616, label:2.500\n",
      "pred:2.803, label:2.570\n",
      "pred:2.814, label:2.800\n",
      "pred:2.606, label:2.730\n",
      "pred:2.814, label:2.970\n",
      "pred:2.606, label:2.370\n",
      "pred:2.606, label:2.770\n",
      "pred:2.606, label:2.970\n",
      "pred:2.606, label:2.630\n",
      "pred:2.606, label:2.800\n",
      "pred:2.814, label:2.930\n",
      "pred:2.611, label:2.300\n",
      "pred:2.814, label:2.500\n",
      "pred:2.606, label:2.700\n",
      "pred:2.803, label:2.300\n",
      "pred:2.606, label:2.130\n",
      "pred:2.814, label:3.230\n",
      "pred:2.606, label:2.500\n",
      "pred:2.814, label:2.730\n",
      "pred:2.606, label:2.100\n",
      "pred:2.803, label:2.900\n",
      "pred:2.606, label:2.300\n",
      "pred:2.705, label:3.000\n",
      "pred:2.686, label:3.300\n",
      "pred:2.727, label:2.930\n",
      "pred:2.814, label:2.800\n",
      "pred:2.606, label:2.570\n",
      "pred:2.683, label:2.600\n",
      "pred:2.814, label:3.130\n",
      "pred:2.606, label:3.070\n",
      "pred:2.803, label:2.430\n",
      "pred:2.814, label:2.670\n",
      "pred:2.475, label:2.700\n",
      "pred:2.803, label:2.470\n",
      "pred:2.913, label:3.100\n",
      "pred:2.683, label:2.600\n",
      "pred:2.606, label:2.470\n",
      "pred:2.606, label:2.030\n",
      "pred:2.803, label:2.670\n",
      "pred:2.803, label:2.770\n",
      "pred:2.606, label:2.930\n",
      "pred:2.814, label:2.530\n",
      "pred:2.717, label:2.870\n",
      "pred:2.606, label:2.600\n",
      "pred:2.803, label:2.730\n",
      "pred:2.606, label:2.570\n",
      "pred:2.631, label:2.270\n",
      "pred:2.631, label:2.530\n",
      "pred:2.606, label:2.200\n",
      "pred:2.606, label:3.030\n",
      "pred:2.683, label:3.070\n",
      "pred:2.606, label:3.600\n",
      "pred:2.606, label:2.730\n",
      "pred:2.804, label:2.930\n",
      "pred:2.616, label:2.870\n",
      "pred:2.606, label:2.970\n",
      "pred:2.606, label:2.730\n",
      "pred:2.803, label:2.670\n",
      "pred:2.814, label:3.300\n",
      "pred:2.606, label:2.600\n",
      "pred:2.631, label:2.100\n",
      "pred:2.606, label:2.930\n",
      "pred:2.814, label:3.200\n",
      "pred:2.803, label:2.670\n",
      "pred:2.606, label:2.200\n",
      "pred:2.814, label:2.700\n",
      "pred:2.803, label:3.030\n",
      "pred:3.489, label:2.900\n",
      "pred:2.631, label:2.470\n",
      "pred:2.641, label:3.200\n",
      "pred:2.814, label:2.970\n",
      "pred:2.641, label:2.930\n",
      "pred:2.606, label:2.570\n",
      "pred:2.606, label:2.570\n",
      "pred:2.683, label:2.170\n",
      "pred:2.814, label:2.630\n",
      "pred:2.606, label:2.930\n",
      "pred:2.500, label:2.330\n",
      "pred:2.814, label:3.100\n",
      "pred:2.683, label:2.770\n",
      "pred:2.606, label:2.670\n",
      "pred:2.606, label:2.670\n",
      "pred:2.803, label:2.970\n",
      "pred:2.803, label:2.770\n",
      "pred:2.606, label:2.070\n",
      "pred:2.606, label:2.600\n",
      "pred:2.540, label:3.500\n",
      "pred:2.616, label:2.870\n",
      "pred:2.606, label:2.830\n",
      "pred:2.606, label:2.870\n",
      "pred:3.002, label:2.670\n",
      "pred:3.151, label:3.170\n",
      "pred:2.814, label:3.330\n",
      "pred:2.606, label:2.600\n"
     ]
    }
   ],
   "source": [
    "X_test = sm.add_constant(test_data[snp_columns])\n",
    "y_predict = TSLWm1.predict(X_test)\n",
    "train_r2_score = TSLWm1.rsquared\n",
    "test_r2_score = r2_score(test_data[\"TSLW\"], y_predict)\n",
    "print(f\"train r2 score: {train_r2_score:.4f}\")\n",
    "print(f\"test r2 score: {test_r2_score:.4f}\")\n",
    "# for pred, label in zip(y_predict, test_data[\"TSLW\"]):\n",
    "#     print(f\"pred:{pred:.3f}, label:{label:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove feature: snp9, p value: 0.772975814264301\n",
      "remove feature: snp5, p value: 0.4650918837641934\n",
      "remove feature: snp4, p value: 0.46509188376404553\n",
      "remove feature: snp2, p value: 0.05969209466994548\n",
      "['snp1', 'snp3', 'snp6', 'snp7', 'snp8']\n"
     ]
    }
   ],
   "source": [
    "# drop SNP feature with p > 0.05\n",
    "selected_features = backward_elimination(train_data[snp_columns], y)\n",
    "print(selected_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train based on selecting SNP and OTU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (544, 206)\n",
      "TSLWm2： X_selected shape: (544, 206)\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.560\n",
      "Model:                            OLS   Adj. R-squared:                  0.293\n",
      "Method:                 Least Squares   F-statistic:                     2.098\n",
      "Date:                Wed, 15 May 2024   Prob (F-statistic):           7.78e-10\n",
      "Time:                        11:41:52   Log-Likelihood:                 52.620\n",
      "No. Observations:                 544   AIC:                             306.8\n",
      "Df Residuals:                     338   BIC:                             1192.\n",
      "Df Model:                         205                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.1267      0.288     10.853      0.000       2.560       3.693\n",
      "snp1           0.4303      0.103      4.157      0.000       0.227       0.634\n",
      "snp3          -0.0840      0.030     -2.761      0.006      -0.144      -0.024\n",
      "snp6          -0.1308      0.020     -6.579      0.000      -0.170      -0.092\n",
      "snp7          -0.0960      0.036     -2.662      0.008      -0.167      -0.025\n",
      "snp8           0.0950      0.053      1.803      0.072      -0.009       0.199\n",
      "OTU_7084      -0.0028      0.028     -0.100      0.921      -0.059       0.053\n",
      "OTU_59         0.0492      0.034      1.463      0.144      -0.017       0.115\n",
      "OTU_320       -0.0246      0.039     -0.634      0.527      -0.101       0.052\n",
      "OTU_383        0.0029      0.028      0.102      0.919      -0.053       0.058\n",
      "OTU_2690      -0.0435      0.032     -1.361      0.174      -0.106       0.019\n",
      "OTU_26423     -0.0521      0.030     -1.762      0.079      -0.110       0.006\n",
      "OTU_131        0.0304      0.033      0.909      0.364      -0.035       0.096\n",
      "OTU_20065     -0.0410      0.031     -1.337      0.182      -0.101       0.019\n",
      "OTU_21968     -0.0140      0.041     -0.340      0.734      -0.095       0.067\n",
      "OTU_4033     1.73e-06      0.028   6.24e-05      1.000      -0.055       0.055\n",
      "OTU_50         0.0461      0.032      1.439      0.151      -0.017       0.109\n",
      "OTU_13344     -0.0010      0.032     -0.032      0.975      -0.063       0.061\n",
      "OTU_1826      -0.0634      0.028     -2.241      0.026      -0.119      -0.008\n",
      "OTU_32        -0.0194      0.030     -0.643      0.520      -0.079       0.040\n",
      "OTU_24324     -0.0126      0.031     -0.409      0.683      -0.074       0.048\n",
      "OTU_19171      0.0403      0.034      1.196      0.232      -0.026       0.107\n",
      "OTU_25881     -0.0432      0.027     -1.576      0.116      -0.097       0.011\n",
      "OTU_5616      -0.0136      0.029     -0.467      0.641      -0.071       0.044\n",
      "OTU_177       -0.0855      0.027     -3.157      0.002      -0.139      -0.032\n",
      "OTU_137       -0.0558      0.029     -1.895      0.059      -0.114       0.002\n",
      "OTU_24        -0.0312      0.036     -0.859      0.391      -0.103       0.040\n",
      "OTU_164       -0.0170      0.030     -0.572      0.568      -0.075       0.041\n",
      "OTU_217       -0.0110      0.032     -0.337      0.736      -0.075       0.053\n",
      "OTU_27598     -0.0225      0.029     -0.777      0.438      -0.080       0.035\n",
      "OTU_14895      0.0474      0.024      1.957      0.051      -0.000       0.095\n",
      "OTU_394       -0.0220      0.026     -0.857      0.392      -0.072       0.028\n",
      "OTU_53        -0.0140      0.030     -0.472      0.637      -0.072       0.044\n",
      "OTU_93         0.0755      0.027      2.749      0.006       0.021       0.130\n",
      "OTU_25134      0.0116      0.029      0.400      0.690      -0.045       0.069\n",
      "OTU_334        0.0217      0.033      0.656      0.513      -0.043       0.087\n",
      "OTU_7357       0.0122      0.024      0.505      0.614      -0.035       0.060\n",
      "OTU_690        0.1451      0.034      4.257      0.000       0.078       0.212\n",
      "OTU_149        0.0100      0.029      0.349      0.727      -0.046       0.066\n",
      "OTU_22881      0.0428      0.029      1.480      0.140      -0.014       0.100\n",
      "OTU_25415      0.0019      0.035      0.055      0.956      -0.067       0.071\n",
      "OTU_2963       0.0514      0.033      1.546      0.123      -0.014       0.117\n",
      "OTU_4067      -0.0406      0.034     -1.208      0.228      -0.107       0.026\n",
      "OTU_15895     -0.0063      0.031     -0.205      0.838      -0.066       0.054\n",
      "OTU_17281      0.0141      0.027      0.517      0.605      -0.040       0.068\n",
      "OTU_341       -0.0265      0.029     -0.913      0.362      -0.084       0.031\n",
      "OTU_22726      0.0020      0.032      0.064      0.949      -0.060       0.064\n",
      "OTU_159       -0.0041      0.023     -0.176      0.861      -0.050       0.042\n",
      "OTU_297       -0.0173      0.011     -1.565      0.119      -0.039       0.004\n",
      "OTU_500       -0.0022      0.022     -0.100      0.920      -0.046       0.042\n",
      "OTU_493       -0.0282      0.031     -0.910      0.364      -0.089       0.033\n",
      "OTU_11945     -0.0544      0.032     -1.710      0.088      -0.117       0.008\n",
      "OTU_24870      0.0771      0.046      1.680      0.094      -0.013       0.167\n",
      "OTU_28808      0.0282      0.026      1.074      0.284      -0.023       0.080\n",
      "OTU_220        0.0270      0.025      1.062      0.289      -0.023       0.077\n",
      "OTU_25608     -0.0050      0.028     -0.178      0.859      -0.061       0.051\n",
      "OTU_4926      -0.0212      0.031     -0.687      0.492      -0.082       0.039\n",
      "OTU_21934     -0.0149      0.035     -0.430      0.668      -0.083       0.053\n",
      "OTU_3874       0.0208      0.032      0.639      0.523      -0.043       0.085\n",
      "OTU_112       -0.0175      0.027     -0.640      0.523      -0.071       0.036\n",
      "OTU_476       -0.0122      0.015     -0.812      0.417      -0.042       0.017\n",
      "OTU_252       -0.0327      0.029     -1.133      0.258      -0.089       0.024\n",
      "OTU_12153      0.0149      0.014      1.089      0.277      -0.012       0.042\n",
      "OTU_70         0.0083      0.032      0.255      0.799      -0.056       0.072\n",
      "OTU_6461      -0.0017      0.022     -0.077      0.939      -0.045       0.041\n",
      "OTU_806       -0.0168      0.032     -0.525      0.600      -0.080       0.046\n",
      "OTU_273       -0.0116      0.032     -0.356      0.722      -0.075       0.052\n",
      "OTU_15777      0.0390      0.035      1.117      0.265      -0.030       0.108\n",
      "OTU_27573     -0.0465      0.028     -1.683      0.093      -0.101       0.008\n",
      "OTU_8358       0.0545      0.027      1.985      0.048       0.001       0.108\n",
      "OTU_201        0.0247      0.029      0.857      0.392      -0.032       0.081\n",
      "OTU_478       -0.0356      0.016     -2.208      0.028      -0.067      -0.004\n",
      "OTU_148        0.0269      0.029      0.924      0.356      -0.030       0.084\n",
      "OTU_19203      0.0102      0.034      0.302      0.763      -0.056       0.076\n",
      "OTU_25463     -0.0229      0.033     -0.684      0.494      -0.089       0.043\n",
      "OTU_54         0.0348      0.025      1.398      0.163      -0.014       0.084\n",
      "OTU_233        0.0345      0.033      1.033      0.302      -0.031       0.100\n",
      "OTU_975        0.0150      0.021      0.718      0.473      -0.026       0.056\n",
      "OTU_22993     -0.0335      0.034     -1.000      0.318      -0.099       0.032\n",
      "OTU_130        0.0702      0.034      2.038      0.042       0.002       0.138\n",
      "OTU_25015      0.0056      0.025      0.221      0.825      -0.044       0.055\n",
      "OTU_12021      0.0654      0.030      2.185      0.030       0.007       0.124\n",
      "OTU_458        0.0102      0.032      0.319      0.750      -0.053       0.073\n",
      "OTU_2542      -0.0467      0.028     -1.675      0.095      -0.102       0.008\n",
      "OTU_1179      -0.0154      0.019     -0.821      0.412      -0.052       0.022\n",
      "OTU_11799     -0.0002      0.025     -0.008      0.994      -0.050       0.049\n",
      "OTU_3745      -0.0151      0.034     -0.450      0.653      -0.081       0.051\n",
      "OTU_27771      0.0253      0.033      0.770      0.442      -0.039       0.090\n",
      "OTU_373       -0.0153      0.028     -0.553      0.581      -0.070       0.039\n",
      "OTU_3386      -0.0016      0.033     -0.048      0.962      -0.067       0.064\n",
      "OTU_73        -0.0620      0.038     -1.639      0.102      -0.136       0.012\n",
      "OTU_10236     -0.0037      0.030     -0.124      0.902      -0.062       0.055\n",
      "OTU_209       -0.0152      0.031     -0.482      0.630      -0.077       0.047\n",
      "OTU_257       -0.1129      0.032     -3.512      0.001      -0.176      -0.050\n",
      "OTU_6190      -0.0218      0.032     -0.680      0.497      -0.085       0.041\n",
      "OTU_8115       0.0949      0.034      2.806      0.005       0.028       0.161\n",
      "OTU_532        0.0382      0.011      3.377      0.001       0.016       0.060\n",
      "OTU_20561      0.1092      0.035      3.122      0.002       0.040       0.178\n",
      "OTU_268        0.0252      0.026      0.969      0.333      -0.026       0.076\n",
      "OTU_251       -0.0891      0.034     -2.631      0.009      -0.156      -0.022\n",
      "OTU_20596      0.0053      0.032      0.165      0.869      -0.057       0.068\n",
      "OTU_917        0.0503      0.025      2.029      0.043       0.002       0.099\n",
      "OTU_144       -0.0434      0.025     -1.729      0.085      -0.093       0.006\n",
      "OTU_2042      -0.0342      0.029     -1.167      0.244      -0.092       0.023\n",
      "OTU_10858      0.0203      0.029      0.700      0.484      -0.037       0.077\n",
      "OTU_3         -0.0305      0.033     -0.912      0.362      -0.096       0.035\n",
      "OTU_643        0.0014      0.028      0.050      0.960      -0.054       0.057\n",
      "OTU_56         0.0449      0.031      1.435      0.152      -0.017       0.107\n",
      "OTU_18308      0.0191      0.035      0.549      0.584      -0.049       0.088\n",
      "OTU_51         0.0397      0.040      0.982      0.327      -0.040       0.119\n",
      "OTU_25484     -0.0017      0.033     -0.052      0.958      -0.067       0.063\n",
      "OTU_28383     -0.0304      0.026     -1.154      0.249      -0.082       0.021\n",
      "OTU_206       -0.0248      0.031     -0.810      0.418      -0.085       0.035\n",
      "OTU_6457       0.0054      0.027      0.198      0.843      -0.048       0.059\n",
      "OTU_8228       0.0172      0.024      0.708      0.480      -0.031       0.065\n",
      "OTU_11218      0.0322      0.033      0.966      0.335      -0.033       0.098\n",
      "OTU_27586     -0.1321      0.041     -3.205      0.001      -0.213      -0.051\n",
      "OTU_352        0.0574      0.032      1.778      0.076      -0.006       0.121\n",
      "OTU_27963      0.0196      0.032      0.605      0.546      -0.044       0.084\n",
      "OTU_184       -0.0027      0.014     -0.192      0.848      -0.031       0.025\n",
      "OTU_3166       0.0371      0.029      1.272      0.204      -0.020       0.095\n",
      "OTU_585       -0.0060      0.032     -0.192      0.848      -0.068       0.056\n",
      "OTU_24550     -0.0069      0.025     -0.273      0.785      -0.057       0.043\n",
      "OTU_28132     -0.0499      0.033     -1.518      0.130      -0.115       0.015\n",
      "OTU_13075     -0.0324      0.029     -1.101      0.272      -0.090       0.025\n",
      "OTU_2628      -0.0622      0.025     -2.533      0.012      -0.110      -0.014\n",
      "OTU_163       -0.0084      0.030     -0.280      0.780      -0.068       0.051\n",
      "OTU_3032       0.0033      0.026      0.126      0.899      -0.048       0.054\n",
      "OTU_21876      0.0234      0.014      1.730      0.085      -0.003       0.050\n",
      "OTU_242       -0.0468      0.035     -1.321      0.188      -0.117       0.023\n",
      "OTU_522        0.0862      0.028      3.116      0.002       0.032       0.141\n",
      "OTU_12854      0.0594      0.028      2.088      0.038       0.003       0.115\n",
      "OTU_4289       0.0448      0.031      1.457      0.146      -0.016       0.105\n",
      "OTU_17532      0.0313      0.030      1.053      0.293      -0.027       0.090\n",
      "OTU_26564     -0.0738      0.032     -2.315      0.021      -0.137      -0.011\n",
      "OTU_14        -0.0108      0.032     -0.333      0.739      -0.074       0.053\n",
      "OTU_16392      0.0527      0.031      1.706      0.089      -0.008       0.113\n",
      "OTU_52         0.0710      0.029      2.454      0.015       0.014       0.128\n",
      "OTU_21573     -0.0453      0.034     -1.351      0.178      -0.111       0.021\n",
      "OTU_1222      -0.0073      0.029     -0.248      0.805      -0.065       0.050\n",
      "OTU_23917      0.0016      0.031      0.052      0.959      -0.060       0.063\n",
      "OTU_27519      0.0337      0.030      1.110      0.268      -0.026       0.093\n",
      "OTU_9821      -0.0012      0.031     -0.039      0.969      -0.063       0.061\n",
      "OTU_350       -0.0345      0.026     -1.344      0.180      -0.085       0.016\n",
      "OTU_2641      -0.0406      0.031     -1.297      0.195      -0.102       0.021\n",
      "OTU_798        0.0514      0.032      1.598      0.111      -0.012       0.115\n",
      "OTU_221       -0.0433      0.030     -1.433      0.153      -0.103       0.016\n",
      "OTU_15216     -0.0004      0.028     -0.013      0.989      -0.055       0.054\n",
      "OTU_229       -0.0238      0.030     -0.790      0.430      -0.083       0.036\n",
      "OTU_25394     -0.0261      0.031     -0.854      0.394      -0.086       0.034\n",
      "OTU_24873      0.0070      0.031      0.224      0.823      -0.054       0.069\n",
      "OTU_216        0.0305      0.032      0.948      0.344      -0.033       0.094\n",
      "OTU_2481       0.0560      0.033      1.714      0.087      -0.008       0.120\n",
      "OTU_2734      -0.0449      0.026     -1.756      0.080      -0.095       0.005\n",
      "OTU_2704       0.0313      0.030      1.040      0.299      -0.028       0.091\n",
      "OTU_303       -0.0697      0.026     -2.720      0.007      -0.120      -0.019\n",
      "OTU_5528      -0.0528      0.031     -1.700      0.090      -0.114       0.008\n",
      "OTU_374       -0.0159      0.034     -0.470      0.639      -0.082       0.051\n",
      "OTU_185       -0.0385      0.036     -1.057      0.291      -0.110       0.033\n",
      "OTU_215        0.0198      0.028      0.706      0.480      -0.035       0.075\n",
      "OTU_2422       0.0460      0.036      1.274      0.204      -0.025       0.117\n",
      "OTU_87        -0.0566      0.029     -1.927      0.055      -0.114       0.001\n",
      "OTU_121        0.0206      0.027      0.751      0.453      -0.033       0.075\n",
      "OTU_28653     -0.0040      0.029     -0.141      0.888      -0.060       0.052\n",
      "OTU_1358       0.0102      0.032      0.318      0.751      -0.053       0.074\n",
      "OTU_25686     -0.0195      0.029     -0.681      0.497      -0.076       0.037\n",
      "OTU_17600     -0.0142      0.040     -0.357      0.721      -0.093       0.064\n",
      "OTU_409        0.0302      0.032      0.944      0.346      -0.033       0.093\n",
      "OTU_436       -0.0390      0.032     -1.229      0.220      -0.101       0.023\n",
      "OTU_26638     -0.0194      0.033     -0.581      0.561      -0.085       0.046\n",
      "OTU_119        0.0583      0.028      2.046      0.042       0.002       0.114\n",
      "OTU_11212     -0.0180      0.032     -0.559      0.576      -0.081       0.045\n",
      "OTU_218        0.0405      0.026      1.538      0.125      -0.011       0.092\n",
      "OTU_1235       0.0209      0.026      0.815      0.415      -0.030       0.071\n",
      "OTU_126       -0.0305      0.030     -1.007      0.315      -0.090       0.029\n",
      "OTU_6105       0.0144      0.035      0.411      0.681      -0.055       0.083\n",
      "OTU_2516       0.0545      0.032      1.689      0.092      -0.009       0.118\n",
      "OTU_6204      -0.0971      0.032     -3.069      0.002      -0.159      -0.035\n",
      "OTU_23581      0.0192      0.033      0.582      0.561      -0.046       0.084\n",
      "OTU_253       -0.0313      0.026     -1.193      0.234      -0.083       0.020\n",
      "OTU_10255      0.0524      0.030      1.772      0.077      -0.006       0.111\n",
      "OTU_60         0.0029      0.020      0.143      0.886      -0.037       0.043\n",
      "OTU_188       -0.0502      0.030     -1.699      0.090      -0.108       0.008\n",
      "OTU_17917      0.0611      0.035      1.733      0.084      -0.008       0.131\n",
      "OTU_28416     -0.0536      0.032     -1.690      0.092      -0.116       0.009\n",
      "OTU_200       -0.1118      0.034     -3.269      0.001      -0.179      -0.045\n",
      "OTU_170        0.0012      0.031      0.038      0.970      -0.060       0.062\n",
      "OTU_27636      0.0203      0.030      0.683      0.495      -0.038       0.079\n",
      "OTU_6477       0.0147      0.023      0.642      0.521      -0.030       0.060\n",
      "OTU_27960      0.0003      0.028      0.010      0.992      -0.055       0.055\n",
      "OTU_2995       0.0083      0.023      0.364      0.716      -0.036       0.053\n",
      "OTU_17625      0.0684      0.037      1.869      0.063      -0.004       0.140\n",
      "OTU_0         -0.0224      0.041     -0.548      0.584      -0.103       0.058\n",
      "OTU_240        0.0439      0.031      1.434      0.153      -0.016       0.104\n",
      "OTU_364       -0.0045      0.023     -0.196      0.844      -0.049       0.040\n",
      "OTU_27620     -0.1062      0.045     -2.352      0.019      -0.195      -0.017\n",
      "OTU_617       -0.0847      0.019     -4.375      0.000      -0.123      -0.047\n",
      "OTU_14661      0.0364      0.033      1.113      0.267      -0.028       0.101\n",
      "OTU_25514      0.0025      0.019      0.126      0.900      -0.036       0.041\n",
      "OTU_23468      0.0342      0.033      1.031      0.303      -0.031       0.100\n",
      "OTU_24877      0.0186      0.036      0.516      0.607      -0.052       0.090\n",
      "OTU_5415       0.0251      0.029      0.852      0.395      -0.033       0.083\n",
      "OTU_14036     -0.0050      0.026     -0.197      0.844      -0.055       0.045\n",
      "OTU_3690       0.0611      0.034      1.810      0.071      -0.005       0.128\n",
      "OTU_5328       0.0346      0.029      1.176      0.240      -0.023       0.092\n",
      "OTU_20590      0.0180      0.032      0.557      0.578      -0.046       0.082\n",
      "==============================================================================\n",
      "Omnibus:                        4.069   Durbin-Watson:                   2.057\n",
      "Prob(Omnibus):                  0.131   Jarque-Bera (JB):                4.910\n",
      "Skew:                           0.032   Prob(JB):                       0.0859\n",
      "Kurtosis:                       3.461   Cond. No.                         698.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 更新模型，加入新的变量CC\n",
    "# X_selected = sm.add_constant(train_data[selected_features])\n",
    "X_selected = sm.add_constant(train_data[selected_features+cc])\n",
    "print(f\"train shape: {X_selected.shape}\")\n",
    "TSLWm2 = sm.OLS(y, X_selected).fit()\n",
    "print(f\"TSLWm2： X_selected shape: {X_selected.shape}\\n\", TSLWm2.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2 score: 0.5599\n",
      "test r2 score: -0.4456\n",
      "pred:3.114, label:2.800\n",
      "pred:2.672, label:2.800\n",
      "pred:2.967, label:2.900\n",
      "pred:3.027, label:3.070\n",
      "pred:3.278, label:2.930\n",
      "pred:3.038, label:3.200\n",
      "pred:2.668, label:2.630\n",
      "pred:2.760, label:2.730\n",
      "pred:2.586, label:2.730\n",
      "pred:2.435, label:2.330\n",
      "pred:2.578, label:2.670\n",
      "pred:2.925, label:2.970\n",
      "pred:2.415, label:2.100\n",
      "pred:2.477, label:2.630\n",
      "pred:2.643, label:2.770\n",
      "pred:3.396, label:2.600\n",
      "pred:2.510, label:2.730\n",
      "pred:2.760, label:2.700\n",
      "pred:2.578, label:2.570\n",
      "pred:2.616, label:2.170\n",
      "pred:2.738, label:2.800\n",
      "pred:2.704, label:2.500\n",
      "pred:2.312, label:2.170\n",
      "pred:2.636, label:2.570\n",
      "pred:2.561, label:2.500\n",
      "pred:3.024, label:2.600\n",
      "pred:2.657, label:2.800\n",
      "pred:2.703, label:3.100\n",
      "pred:2.646, label:2.800\n",
      "pred:2.446, label:2.500\n",
      "pred:2.573, label:2.770\n",
      "pred:2.057, label:2.600\n",
      "pred:2.644, label:3.000\n",
      "pred:2.883, label:2.770\n",
      "pred:2.557, label:2.200\n",
      "pred:2.711, label:2.630\n",
      "pred:2.892, label:2.730\n",
      "pred:2.609, label:2.600\n",
      "pred:2.390, label:2.900\n",
      "pred:2.733, label:2.300\n",
      "pred:2.502, label:2.300\n",
      "pred:2.707, label:3.000\n",
      "pred:2.497, label:2.500\n",
      "pred:2.799, label:2.570\n",
      "pred:2.153, label:2.800\n",
      "pred:2.745, label:2.730\n",
      "pred:2.528, label:2.970\n",
      "pred:2.409, label:2.370\n",
      "pred:2.572, label:2.770\n",
      "pred:2.593, label:2.970\n",
      "pred:2.769, label:2.630\n",
      "pred:2.672, label:2.800\n",
      "pred:2.649, label:2.930\n",
      "pred:2.907, label:2.300\n",
      "pred:2.746, label:2.500\n",
      "pred:2.370, label:2.700\n",
      "pred:2.741, label:2.300\n",
      "pred:2.396, label:2.130\n",
      "pred:3.202, label:3.230\n",
      "pred:2.653, label:2.500\n",
      "pred:2.600, label:2.730\n",
      "pred:2.124, label:2.100\n",
      "pred:2.900, label:2.900\n",
      "pred:2.733, label:2.300\n",
      "pred:2.597, label:3.000\n",
      "pred:2.600, label:3.300\n",
      "pred:2.937, label:2.930\n",
      "pred:2.499, label:2.800\n",
      "pred:2.413, label:2.570\n",
      "pred:2.057, label:2.600\n",
      "pred:2.959, label:3.130\n",
      "pred:2.840, label:3.070\n",
      "pred:2.648, label:2.430\n",
      "pred:2.989, label:2.670\n",
      "pred:2.818, label:2.700\n",
      "pred:2.833, label:2.470\n",
      "pred:3.015, label:3.100\n",
      "pred:2.411, label:2.600\n",
      "pred:2.925, label:2.470\n",
      "pred:3.007, label:2.030\n",
      "pred:2.720, label:2.670\n",
      "pred:2.780, label:2.770\n",
      "pred:2.882, label:2.930\n",
      "pred:2.391, label:2.530\n",
      "pred:3.250, label:2.870\n",
      "pred:2.491, label:2.600\n",
      "pred:2.638, label:2.730\n",
      "pred:2.413, label:2.570\n",
      "pred:2.585, label:2.270\n",
      "pred:2.851, label:2.530\n",
      "pred:2.553, label:2.200\n",
      "pred:1.648, label:3.030\n",
      "pred:2.786, label:3.070\n",
      "pred:2.996, label:3.600\n",
      "pred:2.462, label:2.730\n",
      "pred:2.416, label:2.930\n",
      "pred:2.428, label:2.870\n",
      "pred:2.561, label:2.970\n",
      "pred:2.586, label:2.730\n",
      "pred:2.720, label:2.670\n",
      "pred:2.325, label:3.300\n",
      "pred:3.024, label:2.600\n",
      "pred:3.118, label:2.100\n",
      "pred:2.597, label:2.930\n",
      "pred:3.038, label:3.200\n",
      "pred:2.653, label:2.670\n",
      "pred:2.557, label:2.200\n",
      "pred:2.908, label:2.700\n",
      "pred:2.567, label:3.030\n",
      "pred:3.730, label:2.900\n",
      "pred:2.360, label:2.470\n",
      "pred:3.139, label:3.200\n",
      "pred:3.021, label:2.970\n",
      "pred:2.401, label:2.930\n",
      "pred:2.622, label:2.570\n",
      "pred:2.622, label:2.570\n",
      "pred:2.743, label:2.170\n",
      "pred:3.118, label:2.630\n",
      "pred:2.671, label:2.930\n",
      "pred:2.505, label:2.330\n",
      "pred:2.871, label:3.100\n",
      "pred:2.367, label:2.770\n",
      "pred:2.726, label:2.670\n",
      "pred:2.613, label:2.670\n",
      "pred:2.805, label:2.970\n",
      "pred:2.779, label:2.770\n",
      "pred:2.488, label:2.070\n",
      "pred:2.696, label:2.600\n",
      "pred:2.562, label:3.500\n",
      "pred:2.293, label:2.870\n",
      "pred:2.824, label:2.830\n",
      "pred:2.526, label:2.870\n",
      "pred:3.486, label:2.670\n",
      "pred:3.383, label:3.170\n",
      "pred:2.929, label:3.330\n",
      "pred:2.504, label:2.600\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "X_test = sm.add_constant(test_data[selected_features + cc])\n",
    "y_predict = TSLWm2.predict(X_test)\n",
    "train_r2_score = TSLWm2.rsquared\n",
    "test_r2_score = r2_score(test_data[\"TSLW\"], y_predict)\n",
    "print(f\"train r2 score: {train_r2_score:.4f}\")\n",
    "print(f\"test r2 score: {test_r2_score:.4f}\")\n",
    "for pred, label in zip(y_predict, test_data[\"TSLW\"]):\n",
    "    print(f\"pred:{pred:.3f}, label:{label:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove feature: OTU_4033, p value: 0.9999502482158023\n",
      "remove feature: OTU_11799, p value: 0.9936137542621828\n",
      "remove feature: OTU_27960, p value: 0.9926031871731282\n",
      "remove feature: OTU_15216, p value: 0.9888251696640102\n",
      "remove feature: OTU_13344, p value: 0.9758971916362942\n",
      "remove feature: OTU_170, p value: 0.968346033751196\n",
      "remove feature: OTU_9821, p value: 0.9682280534470041\n",
      "remove feature: OTU_3386, p value: 0.971235672446499\n",
      "remove feature: OTU_643, p value: 0.965455409452098\n",
      "remove feature: OTU_25415, p value: 0.9626925577518658\n",
      "remove feature: OTU_23917, p value: 0.9588280788653085\n",
      "remove feature: OTU_25484, p value: 0.9630001391013988\n",
      "remove feature: OTU_22726, p value: 0.9483780814297712\n",
      "remove feature: OTU_7084, p value: 0.9312583100472844\n",
      "remove feature: OTU_500, p value: 0.941531411850612\n",
      "remove feature: OTU_383, p value: 0.9241328093240174\n",
      "remove feature: OTU_3032, p value: 0.9088787853227698\n",
      "remove feature: OTU_6461, p value: 0.9117979750236527\n",
      "remove feature: OTU_585, p value: 0.8757141868291827\n",
      "remove feature: OTU_159, p value: 0.8787924060852979\n",
      "remove feature: OTU_20596, p value: 0.869626693918936\n",
      "remove feature: OTU_28653, p value: 0.870030511481314\n",
      "remove feature: OTU_10236, p value: 0.8722246052952307\n",
      "remove feature: OTU_14036, p value: 0.8597202289341176\n",
      "remove feature: OTU_60, p value: 0.8456942918453231\n",
      "remove feature: OTU_25514, p value: 0.83609205850032\n",
      "remove feature: OTU_364, p value: 0.8304762795508432\n",
      "remove feature: OTU_184, p value: 0.8412371491186224\n",
      "remove feature: OTU_6457, p value: 0.8203002046494122\n",
      "remove feature: OTU_1222, p value: 0.7883691410265153\n",
      "remove feature: OTU_15895, p value: 0.7837175673835678\n",
      "remove feature: OTU_25608, p value: 0.7851337189252767\n",
      "remove feature: OTU_25015, p value: 0.7904961500953109\n",
      "remove feature: OTU_19203, p value: 0.7709105141337123\n",
      "remove feature: OTU_1358, p value: 0.7775423717107768\n",
      "remove feature: OTU_21968, p value: 0.796985446950893\n",
      "remove feature: OTU_24873, p value: 0.7768920700413291\n",
      "remove feature: OTU_24550, p value: 0.7835764189070872\n",
      "remove feature: OTU_458, p value: 0.7896340377394465\n",
      "remove feature: OTU_70, p value: 0.771036558804646\n",
      "remove feature: OTU_273, p value: 0.7461963015547282\n",
      "remove feature: OTU_17600, p value: 0.737007447100241\n",
      "remove feature: OTU_3745, p value: 0.7436113802730113\n",
      "remove feature: OTU_163, p value: 0.7307048123730224\n",
      "remove feature: OTU_14, p value: 0.7004719717459081\n",
      "remove feature: OTU_7357, p value: 0.686445088886001\n",
      "remove feature: OTU_149, p value: 0.6920364247562747\n",
      "remove feature: OTU_217, p value: 0.6939454702572951\n",
      "remove feature: OTU_5616, p value: 0.6474020816549397\n",
      "remove feature: OTU_21934, p value: 0.6563311152026878\n",
      "remove feature: OTU_2995, p value: 0.6677690039726\n",
      "remove feature: OTU_17281, p value: 0.6528161022060275\n",
      "remove feature: OTU_374, p value: 0.6150890470932945\n",
      "remove feature: OTU_112, p value: 0.5820745952949455\n",
      "remove feature: OTU_23581, p value: 0.5856078049656959\n",
      "remove feature: OTU_6105, p value: 0.5568349095960842\n",
      "remove feature: OTU_24324, p value: 0.5888500748999945\n",
      "remove feature: OTU_53, p value: 0.5679774561613185\n",
      "remove feature: OTU_27963, p value: 0.575751408967561\n",
      "remove feature: OTU_24877, p value: 0.5114426105188989\n",
      "remove feature: OTU_0, p value: 0.5131612152865372\n",
      "remove feature: OTU_209, p value: 0.5441384453265548\n",
      "remove feature: OTU_334, p value: 0.5715163695235358\n",
      "remove feature: OTU_26638, p value: 0.5542551560470077\n",
      "remove feature: OTU_4926, p value: 0.5279905638565571\n",
      "remove feature: OTU_25463, p value: 0.538675115078965\n",
      "remove feature: OTU_25686, p value: 0.48229262305838205\n",
      "remove feature: OTU_3874, p value: 0.5249137678295901\n",
      "remove feature: OTU_51, p value: 0.5145165755125591\n",
      "remove feature: OTU_32, p value: 0.4906034534617387\n",
      "remove feature: OTU_25134, p value: 0.45901955581642384\n",
      "remove feature: OTU_201, p value: 0.46326461787518913\n",
      "remove feature: OTU_27771, p value: 0.4458488401820684\n",
      "remove feature: OTU_164, p value: 0.4595137618193731\n",
      "remove feature: OTU_27598, p value: 0.4504261028873433\n",
      "remove feature: OTU_1235, p value: 0.4958113648727478\n",
      "remove feature: OTU_476, p value: 0.5067416527504032\n",
      "remove feature: OTU_18308, p value: 0.43992305235511286\n",
      "remove feature: OTU_409, p value: 0.4491385009235711\n",
      "remove feature: OTU_215, p value: 0.4526298716146099\n",
      "remove feature: OTU_6477, p value: 0.4653307501428593\n",
      "remove feature: OTU_206, p value: 0.49165188165787777\n",
      "remove feature: OTU_394, p value: 0.39745217898338137\n",
      "remove feature: OTU_24, p value: 0.40274992680724975\n",
      "remove feature: OTU_975, p value: 0.43945013962401647\n",
      "remove feature: OTU_27519, p value: 0.34955375198988425\n",
      "remove feature: OTU_28808, p value: 0.32343700944987874\n",
      "remove feature: OTU_233, p value: 0.32535395770264297\n",
      "remove feature: OTU_11212, p value: 0.33927054837390624\n",
      "remove feature: OTU_20590, p value: 0.34312713985691934\n",
      "remove feature: OTU_373, p value: 0.3447110825342018\n",
      "remove feature: OTU_216, p value: 0.38371628449646933\n",
      "remove feature: OTU_229, p value: 0.3015418529722588\n",
      "remove feature: OTU_27636, p value: 0.2908928354978422\n",
      "remove feature: OTU_1179, p value: 0.3114618238714272\n",
      "remove feature: OTU_806, p value: 0.27198865609319245\n",
      "remove feature: OTU_131, p value: 0.2741883790226731\n",
      "remove feature: OTU_121, p value: 0.29661864809858807\n",
      "remove feature: OTU_25394, p value: 0.3092592456509549\n",
      "remove feature: OTU_350, p value: 0.3124739046014593\n",
      "remove feature: OTU_252, p value: 0.28539125522966563\n",
      "remove feature: OTU_8228, p value: 0.25984818640925084\n",
      "remove feature: OTU_2422, p value: 0.22369853218655136\n",
      "remove feature: OTU_15777, p value: 0.25894334076030984\n",
      "remove feature: OTU_493, p value: 0.2929467190352472\n",
      "remove feature: OTU_253, p value: 0.2542947699757011\n",
      "remove feature: OTU_17532, p value: 0.21388644492147377\n",
      "remove feature: OTU_436, p value: 0.2676592524140327\n",
      "remove feature: OTU_5415, p value: 0.2395361307398253\n",
      "remove feature: OTU_11218, p value: 0.2194660851327634\n",
      "remove feature: OTU_6190, p value: 0.2148312284519778\n",
      "remove feature: OTU_320, p value: 0.18573532116267402\n",
      "remove feature: OTU_268, p value: 0.2105072746502944\n",
      "remove feature: OTU_14661, p value: 0.21389574059022504\n",
      "remove feature: OTU_2734, p value: 0.23521655378421416\n",
      "remove feature: OTU_220, p value: 0.2216527745456746\n",
      "remove feature: OTU_242, p value: 0.27678609067488547\n",
      "remove feature: OTU_126, p value: 0.25074466561773734\n",
      "remove feature: OTU_10858, p value: 0.24268183180864647\n",
      "remove feature: OTU_17917, p value: 0.21042648878056044\n",
      "remove feature: OTU_2481, p value: 0.19478469611612248\n",
      "remove feature: OTU_50, p value: 0.19032060755622404\n",
      "remove feature: OTU_2516, p value: 0.18754629975134882\n",
      "remove feature: OTU_16392, p value: 0.15899752361702818\n",
      "remove feature: OTU_3, p value: 0.1722990057170959\n",
      "remove feature: OTU_2704, p value: 0.20696680515294036\n",
      "remove feature: OTU_5528, p value: 0.15880221066861622\n",
      "remove feature: OTU_12153, p value: 0.17462815571915086\n",
      "remove feature: OTU_3690, p value: 0.19492188621319195\n",
      "remove feature: OTU_54, p value: 0.19947669224775305\n",
      "remove feature: OTU_25881, p value: 0.23972944892062692\n",
      "remove feature: OTU_917, p value: 0.18966713944704056\n",
      "remove feature: OTU_137, p value: 0.2061888439615298\n",
      "remove feature: OTU_28383, p value: 0.21516280718132055\n",
      "remove feature: OTU_2042, p value: 0.24193206795128638\n",
      "remove feature: OTU_26564, p value: 0.21234324074556613\n",
      "remove feature: OTU_352, p value: 0.24659778688000658\n",
      "remove feature: OTU_4289, p value: 0.215485039533325\n",
      "remove feature: OTU_148, p value: 0.16574324321420617\n",
      "remove feature: OTU_28416, p value: 0.16563348018201027\n",
      "remove feature: OTU_13075, p value: 0.19990160116982372\n",
      "remove feature: OTU_341, p value: 0.18811257391251615\n",
      "remove feature: OTU_130, p value: 0.13364167129734636\n",
      "remove feature: OTU_1826, p value: 0.1372842178127153\n",
      "remove feature: OTU_798, p value: 0.18147095291436674\n",
      "remove feature: OTU_478, p value: 0.11732098696681736\n",
      "remove feature: OTU_5328, p value: 0.13922933581305189\n",
      "remove feature: OTU_21876, p value: 0.08212363119157338\n",
      "remove feature: OTU_20065, p value: 0.10383259180229609\n",
      "remove feature: OTU_27620, p value: 0.07711104939713312\n",
      "remove feature: OTU_221, p value: 0.07744712186176006\n",
      "remove feature: OTU_10255, p value: 0.09744321538723891\n",
      "remove feature: OTU_185, p value: 0.10458914914808971\n",
      "remove feature: OTU_59, p value: 0.0964851865155899\n",
      "remove feature: OTU_56, p value: 0.11146966318848635\n",
      "remove feature: OTU_14895, p value: 0.12840713405956639\n",
      "remove feature: OTU_21573, p value: 0.0632505978580488\n",
      "remove feature: OTU_27573, p value: 0.06531796653686565\n",
      "remove feature: OTU_4067, p value: 0.06122103455242421\n",
      "remove feature: OTU_3166, p value: 0.05749164009902722\n",
      "remove feature: OTU_2641, p value: 0.0717909963027911\n",
      "remove feature: OTU_22881, p value: 0.06267887101926986\n",
      "remove feature: OTU_144, p value: 0.08677581221208633\n",
      "remove feature: OTU_12021, p value: 0.06983075114105419\n",
      "['snp1', 'snp3', 'snp6', 'snp7', 'snp8', 'OTU_2690', 'OTU_26423', 'OTU_19171', 'OTU_177', 'OTU_93', 'OTU_690', 'OTU_2963', 'OTU_297', 'OTU_11945', 'OTU_24870', 'OTU_8358', 'OTU_22993', 'OTU_2542', 'OTU_73', 'OTU_257', 'OTU_8115', 'OTU_532', 'OTU_20561', 'OTU_251', 'OTU_27586', 'OTU_28132', 'OTU_2628', 'OTU_522', 'OTU_12854', 'OTU_52', 'OTU_303', 'OTU_87', 'OTU_119', 'OTU_218', 'OTU_6204', 'OTU_188', 'OTU_200', 'OTU_17625', 'OTU_240', 'OTU_617', 'OTU_23468']\n"
     ]
    }
   ],
   "source": [
    "selected_features = backward_elimination(train_data[selected_features + cc], y)\n",
    "print(selected_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (544, 42)\n",
      "TSLWm2： X_selected shape: (544, 42)\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.376\n",
      "Model:                            OLS   Adj. R-squared:                  0.325\n",
      "Method:                 Least Squares   F-statistic:                     7.372\n",
      "Date:                Wed, 15 May 2024   Prob (F-statistic):           6.20e-31\n",
      "Time:                        11:48:28   Log-Likelihood:                -42.457\n",
      "No. Observations:                 544   AIC:                             168.9\n",
      "Df Residuals:                     502   BIC:                             349.5\n",
      "Df Model:                          41                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.9831      0.085     35.101      0.000       2.816       3.150\n",
      "snp1           0.3096      0.069      4.478      0.000       0.174       0.445\n",
      "snp3          -0.0635      0.019     -3.302      0.001      -0.101      -0.026\n",
      "snp6          -0.1212      0.014     -8.844      0.000      -0.148      -0.094\n",
      "snp7          -0.1377      0.026     -5.355      0.000      -0.188      -0.087\n",
      "snp8           0.0804      0.034      2.330      0.020       0.013       0.148\n",
      "OTU_2690      -0.0475      0.019     -2.495      0.013      -0.085      -0.010\n",
      "OTU_26423     -0.0433      0.018     -2.463      0.014      -0.078      -0.009\n",
      "OTU_19171      0.0663      0.022      3.072      0.002       0.024       0.109\n",
      "OTU_177       -0.0592      0.016     -3.694      0.000      -0.091      -0.028\n",
      "OTU_93         0.0455      0.013      3.520      0.000       0.020       0.071\n",
      "OTU_690        0.0821      0.021      3.920      0.000       0.041       0.123\n",
      "OTU_2963       0.0459      0.020      2.334      0.020       0.007       0.084\n",
      "OTU_297       -0.0185      0.007     -2.769      0.006      -0.032      -0.005\n",
      "OTU_11945     -0.0419      0.011     -3.972      0.000      -0.063      -0.021\n",
      "OTU_24870      0.0441      0.018      2.429      0.015       0.008       0.080\n",
      "OTU_8358       0.0302      0.013      2.247      0.025       0.004       0.057\n",
      "OTU_22993     -0.0443      0.020     -2.259      0.024      -0.083      -0.006\n",
      "OTU_2542      -0.0648      0.018     -3.616      0.000      -0.100      -0.030\n",
      "OTU_73        -0.0593      0.020     -2.973      0.003      -0.099      -0.020\n",
      "OTU_257       -0.0460      0.018     -2.621      0.009      -0.080      -0.012\n",
      "OTU_8115       0.0625      0.020      3.063      0.002       0.022       0.103\n",
      "OTU_532        0.0162      0.007      2.457      0.014       0.003       0.029\n",
      "OTU_20561      0.0439      0.020      2.198      0.028       0.005       0.083\n",
      "OTU_251       -0.0580      0.021     -2.789      0.005      -0.099      -0.017\n",
      "OTU_27586     -0.0627      0.020     -3.116      0.002      -0.102      -0.023\n",
      "OTU_28132     -0.0423      0.016     -2.598      0.010      -0.074      -0.010\n",
      "OTU_2628      -0.0441      0.015     -2.923      0.004      -0.074      -0.014\n",
      "OTU_522        0.0705      0.015      4.714      0.000       0.041       0.100\n",
      "OTU_12854      0.0525      0.015      3.439      0.001       0.022       0.082\n",
      "OTU_52         0.0431      0.015      2.833      0.005       0.013       0.073\n",
      "OTU_303       -0.0382      0.015     -2.532      0.012      -0.068      -0.009\n",
      "OTU_87        -0.0369      0.015     -2.413      0.016      -0.067      -0.007\n",
      "OTU_119        0.0347      0.015      2.356      0.019       0.006       0.064\n",
      "OTU_218        0.0359      0.013      2.675      0.008       0.010       0.062\n",
      "OTU_6204      -0.0841      0.020     -4.234      0.000      -0.123      -0.045\n",
      "OTU_188       -0.0702      0.019     -3.659      0.000      -0.108      -0.033\n",
      "OTU_200       -0.0795      0.019     -4.192      0.000      -0.117      -0.042\n",
      "OTU_17625      0.0731      0.019      3.794      0.000       0.035       0.111\n",
      "OTU_240        0.0536      0.019      2.785      0.006       0.016       0.091\n",
      "OTU_617       -0.0604      0.011     -5.482      0.000      -0.082      -0.039\n",
      "OTU_23468      0.0450      0.017      2.651      0.008       0.012       0.078\n",
      "==============================================================================\n",
      "Omnibus:                        4.457   Durbin-Watson:                   1.973\n",
      "Prob(Omnibus):                  0.108   Jarque-Bera (JB):                4.374\n",
      "Skew:                           0.169   Prob(JB):                        0.112\n",
      "Kurtosis:                       3.281   Cond. No.                         102.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# feature include OUT and SNP with select feature\n",
    "X_selected = sm.add_constant(train_data[selected_features])\n",
    "print(f\"train shape: {X_selected.shape}\")\n",
    "TSLWm3 = sm.OLS(y, X_selected).fit()\n",
    "print(f\"TSLWm2： X_selected shape: {X_selected.shape}\\n\", TSLWm3.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2 score: 0.3758\n",
      "test r2 score: -0.0512\n",
      "pred:2.965, label:2.800\n",
      "pred:2.566, label:2.800\n",
      "pred:2.700, label:2.900\n",
      "pred:2.883, label:3.070\n",
      "pred:2.896, label:2.930\n",
      "pred:2.601, label:3.200\n",
      "pred:2.700, label:2.630\n",
      "pred:2.686, label:2.730\n",
      "pred:2.587, label:2.730\n",
      "pred:2.349, label:2.330\n",
      "pred:2.844, label:2.670\n",
      "pred:2.778, label:2.970\n",
      "pred:2.563, label:2.100\n",
      "pred:2.673, label:2.630\n",
      "pred:2.574, label:2.770\n",
      "pred:2.906, label:2.600\n",
      "pred:2.599, label:2.730\n",
      "pred:2.694, label:2.700\n",
      "pred:2.620, label:2.570\n",
      "pred:2.502, label:2.170\n",
      "pred:2.636, label:2.800\n",
      "pred:2.811, label:2.500\n",
      "pred:2.399, label:2.170\n",
      "pred:2.754, label:2.570\n",
      "pred:2.767, label:2.500\n",
      "pred:2.480, label:2.600\n",
      "pred:2.981, label:2.800\n",
      "pred:2.673, label:3.100\n",
      "pred:2.511, label:2.800\n",
      "pred:2.308, label:2.500\n",
      "pred:2.558, label:2.770\n",
      "pred:2.471, label:2.600\n",
      "pred:2.670, label:3.000\n",
      "pred:2.997, label:2.770\n",
      "pred:2.793, label:2.200\n",
      "pred:2.654, label:2.630\n",
      "pred:2.755, label:2.730\n",
      "pred:2.432, label:2.600\n",
      "pred:2.354, label:2.900\n",
      "pred:2.540, label:2.300\n",
      "pred:2.690, label:2.300\n",
      "pred:2.797, label:3.000\n",
      "pred:2.550, label:2.500\n",
      "pred:2.788, label:2.570\n",
      "pred:2.377, label:2.800\n",
      "pred:2.606, label:2.730\n",
      "pred:2.912, label:2.970\n",
      "pred:2.510, label:2.370\n",
      "pred:2.709, label:2.770\n",
      "pred:2.505, label:2.970\n",
      "pred:2.772, label:2.630\n",
      "pred:2.566, label:2.800\n",
      "pred:2.793, label:2.930\n",
      "pred:2.755, label:2.300\n",
      "pred:3.012, label:2.500\n",
      "pred:2.617, label:2.700\n",
      "pred:2.634, label:2.300\n",
      "pred:2.590, label:2.130\n",
      "pred:2.914, label:3.230\n",
      "pred:2.598, label:2.500\n",
      "pred:2.678, label:2.730\n",
      "pred:2.269, label:2.100\n",
      "pred:3.049, label:2.900\n",
      "pred:2.540, label:2.300\n",
      "pred:2.631, label:3.000\n",
      "pred:2.768, label:3.300\n",
      "pred:2.754, label:2.930\n",
      "pred:2.729, label:2.800\n",
      "pred:2.417, label:2.570\n",
      "pred:2.471, label:2.600\n",
      "pred:2.844, label:3.130\n",
      "pred:2.755, label:3.070\n",
      "pred:2.614, label:2.430\n",
      "pred:2.951, label:2.670\n",
      "pred:2.762, label:2.700\n",
      "pred:2.799, label:2.470\n",
      "pred:3.206, label:3.100\n",
      "pred:2.795, label:2.600\n",
      "pred:2.843, label:2.470\n",
      "pred:2.980, label:2.030\n",
      "pred:2.831, label:2.670\n",
      "pred:2.796, label:2.770\n",
      "pred:2.755, label:2.930\n",
      "pred:2.480, label:2.530\n",
      "pred:2.974, label:2.870\n",
      "pred:2.743, label:2.600\n",
      "pred:2.716, label:2.730\n",
      "pred:2.417, label:2.570\n",
      "pred:2.586, label:2.270\n",
      "pred:2.952, label:2.530\n",
      "pred:2.624, label:2.200\n",
      "pred:2.306, label:3.030\n",
      "pred:2.748, label:3.070\n",
      "pred:2.920, label:3.600\n",
      "pred:2.644, label:2.730\n",
      "pred:2.724, label:2.930\n",
      "pred:2.383, label:2.870\n",
      "pred:2.671, label:2.970\n",
      "pred:2.587, label:2.730\n",
      "pred:2.831, label:2.670\n",
      "pred:2.737, label:3.300\n",
      "pred:2.480, label:2.600\n",
      "pred:2.924, label:2.100\n",
      "pred:2.720, label:2.930\n",
      "pred:2.601, label:3.200\n",
      "pred:2.649, label:2.670\n",
      "pred:2.793, label:2.200\n",
      "pred:2.932, label:2.700\n",
      "pred:2.637, label:3.030\n",
      "pred:3.330, label:2.900\n",
      "pred:2.667, label:2.470\n",
      "pred:2.974, label:3.200\n",
      "pred:2.476, label:2.970\n",
      "pred:2.529, label:2.930\n",
      "pred:2.597, label:2.570\n",
      "pred:2.597, label:2.570\n",
      "pred:2.813, label:2.170\n",
      "pred:3.001, label:2.630\n",
      "pred:2.761, label:2.930\n",
      "pred:2.453, label:2.330\n",
      "pred:2.739, label:3.100\n",
      "pred:2.491, label:2.770\n",
      "pred:2.700, label:2.670\n",
      "pred:2.754, label:2.670\n",
      "pred:2.788, label:2.970\n",
      "pred:2.559, label:2.770\n",
      "pred:2.556, label:2.070\n",
      "pred:2.498, label:2.600\n",
      "pred:2.830, label:3.500\n",
      "pred:2.665, label:2.870\n",
      "pred:2.723, label:2.830\n",
      "pred:2.486, label:2.870\n",
      "pred:3.043, label:2.670\n",
      "pred:3.187, label:3.170\n",
      "pred:2.955, label:3.330\n",
      "pred:2.563, label:2.600\n"
     ]
    }
   ],
   "source": [
    "X_test = sm.add_constant(test_data[selected_features])\n",
    "y_predict = TSLWm3.predict(X_test)\n",
    "train_r2_score = TSLWm3.rsquared\n",
    "test_r2_score = r2_score(test_data[\"TSLW\"], y_predict)\n",
    "print(f\"train r2 score: {train_r2_score:.4f}\")\n",
    "print(f\"test r2 score: {test_r2_score:.4f}\")\n",
    "for pred, label in zip(y_predict, test_data[\"TSLW\"]):\n",
    "    print(f\"pred:{pred:.3f}, label:{label:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.123\n",
      "Model:                            OLS   Adj. R-squared:                  0.112\n",
      "Method:                 Least Squares   F-statistic:                     11.73\n",
      "Date:                Tue, 14 May 2024   Prob (F-statistic):           1.07e-15\n",
      "Time:                        19:37:01   Log-Likelihood:                -176.27\n",
      "No. Observations:                 680   AIC:                             370.5\n",
      "Df Residuals:                     671   BIC:                             411.2\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.3221      0.449      5.172      0.000       1.441       3.204\n",
      "snp1           0.2747      0.057      4.802      0.000       0.162       0.387\n",
      "snp2           0.2019      0.224      0.901      0.368      -0.238       0.642\n",
      "snp3          -0.0546      0.019     -2.836      0.005      -0.092      -0.017\n",
      "snp4           0.0209      0.024      0.879      0.380      -0.026       0.068\n",
      "snp5           0.0209      0.024      0.879      0.380      -0.026       0.068\n",
      "snp6           0.1410      0.225      0.627      0.531      -0.300       0.582\n",
      "snp7          -0.0839      0.024     -3.444      0.001      -0.132      -0.036\n",
      "snp8           0.1053      0.029      3.599      0.000       0.048       0.163\n",
      "snp9           0.0415      0.016      2.624      0.009       0.010       0.073\n",
      "==============================================================================\n",
      "Omnibus:                        1.320   Durbin-Watson:                   1.581\n",
      "Prob(Omnibus):                  0.517   Jarque-Bera (JB):                1.184\n",
      "Skew:                          -0.029   Prob(JB):                        0.553\n",
      "Kurtosis:                       3.196   Cond. No.                     4.71e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.18e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "TSLWm1: X_selected shape: (680, 4)\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.066\n",
      "Model:                            OLS   Adj. R-squared:                  0.062\n",
      "Method:                 Least Squares   F-statistic:                     15.99\n",
      "Date:                Tue, 14 May 2024   Prob (F-statistic):           4.72e-10\n",
      "Time:                        19:37:01   Log-Likelihood:                -197.46\n",
      "No. Observations:                 680   AIC:                             402.9\n",
      "Df Residuals:                     676   BIC:                             421.0\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.7968      0.021    133.792      0.000       2.756       2.838\n",
      "snp3          -0.0565      0.020     -2.858      0.004      -0.095      -0.018\n",
      "snp6          -0.0809      0.013     -6.080      0.000      -0.107      -0.055\n",
      "snp7          -0.0886      0.025     -3.550      0.000      -0.138      -0.040\n",
      "==============================================================================\n",
      "Omnibus:                        5.683   Durbin-Watson:                   1.481\n",
      "Prob(Omnibus):                  0.058   Jarque-Bera (JB):                7.426\n",
      "Skew:                           0.037   Prob(JB):                       0.0244\n",
      "Kurtosis:                       3.507   Cond. No.                         3.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "TSLWm2： X_selected shape: (680, 204)\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.166\n",
      "Model:                            OLS   Adj. R-squared:                 -0.190\n",
      "Method:                 Least Squares   F-statistic:                    0.4657\n",
      "Date:                Tue, 14 May 2024   Prob (F-statistic):               1.00\n",
      "Time:                        19:37:01   Log-Likelihood:                -159.18\n",
      "No. Observations:                 680   AIC:                             726.4\n",
      "Df Residuals:                     476   BIC:                             1649.\n",
      "Df Model:                         203                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.9711      0.259     11.456      0.000       2.461       3.481\n",
      "snp3          -0.0686      0.026     -2.611      0.009      -0.120      -0.017\n",
      "snp6          -0.1108      0.018     -6.090      0.000      -0.147      -0.075\n",
      "snp7          -0.1209      0.034     -3.513      0.000      -0.189      -0.053\n",
      "OTU_7084      -0.0111      0.026     -0.429      0.668      -0.062       0.040\n",
      "OTU_59        -0.0035      0.028     -0.123      0.902      -0.059       0.052\n",
      "OTU_320        0.0117      0.033      0.358      0.720      -0.052       0.076\n",
      "OTU_383        0.0049      0.024      0.202      0.840      -0.043       0.053\n",
      "OTU_2690      -0.0001      0.027     -0.004      0.997      -0.054       0.053\n",
      "OTU_26423     -0.0153      0.027     -0.568      0.570      -0.068       0.038\n",
      "OTU_131       -0.0021      0.029     -0.071      0.943      -0.060       0.056\n",
      "OTU_20065     -0.0088      0.026     -0.331      0.741      -0.061       0.043\n",
      "OTU_21968      0.0170      0.034      0.495      0.621      -0.050       0.084\n",
      "OTU_4033       0.0145      0.024      0.597      0.551      -0.033       0.062\n",
      "OTU_50         0.0138      0.030      0.459      0.646      -0.045       0.073\n",
      "OTU_13344      0.0097      0.027      0.366      0.714      -0.043       0.062\n",
      "OTU_1826      -0.0034      0.025     -0.137      0.891      -0.053       0.046\n",
      "OTU_32         0.0095      0.025      0.388      0.698      -0.039       0.058\n",
      "OTU_24324     -0.0249      0.028     -0.884      0.377      -0.080       0.030\n",
      "OTU_19171      0.0101      0.029      0.345      0.730      -0.047       0.068\n",
      "OTU_25881      0.0051      0.025      0.202      0.840      -0.045       0.055\n",
      "OTU_5616       0.0042      0.026      0.163      0.871      -0.046       0.054\n",
      "OTU_177       -0.0015      0.024     -0.061      0.952      -0.049       0.046\n",
      "OTU_137       -0.0132      0.026     -0.508      0.611      -0.064       0.038\n",
      "OTU_24         0.0004      0.032      0.011      0.991      -0.063       0.064\n",
      "OTU_164       -0.0253      0.027     -0.925      0.355      -0.079       0.028\n",
      "OTU_217       -0.0038      0.029     -0.132      0.895      -0.060       0.053\n",
      "OTU_27598      0.0003      0.027      0.009      0.993      -0.053       0.054\n",
      "OTU_14895      0.0121      0.022      0.555      0.579      -0.031       0.055\n",
      "OTU_394        0.0087      0.023      0.373      0.710      -0.037       0.055\n",
      "OTU_53        -0.0143      0.026     -0.544      0.587      -0.066       0.037\n",
      "OTU_93         0.0023      0.026      0.087      0.931      -0.049       0.054\n",
      "OTU_25134      0.0008      0.025      0.033      0.974      -0.048       0.049\n",
      "OTU_334        0.0120      0.027      0.443      0.658      -0.041       0.065\n",
      "OTU_7357       0.0073      0.023      0.322      0.747      -0.037       0.052\n",
      "OTU_690        0.0137      0.030      0.452      0.651      -0.046       0.073\n",
      "OTU_149        0.0143      0.025      0.569      0.569      -0.035       0.064\n",
      "OTU_22881      0.0114      0.026      0.435      0.664      -0.040       0.063\n",
      "OTU_25415      0.0131      0.029      0.450      0.653      -0.044       0.070\n",
      "OTU_2963      -0.0045      0.030     -0.151      0.880      -0.063       0.054\n",
      "OTU_4067      -0.0098      0.029     -0.342      0.732      -0.066       0.046\n",
      "OTU_15895     -0.0262      0.028     -0.951      0.342      -0.080       0.028\n",
      "OTU_17281     -0.0028      0.026     -0.108      0.914      -0.053       0.048\n",
      "OTU_341        0.0021      0.027      0.079      0.937      -0.051       0.055\n",
      "OTU_22726      0.0159      0.027      0.579      0.563      -0.038       0.070\n",
      "OTU_159       -0.0029      0.021     -0.137      0.891      -0.044       0.039\n",
      "OTU_297       -0.0084      0.010     -0.876      0.381      -0.027       0.010\n",
      "OTU_500       -0.0049      0.021     -0.237      0.813      -0.046       0.036\n",
      "OTU_493       -0.0143      0.029     -0.499      0.618      -0.071       0.042\n",
      "OTU_11945      0.0144      0.028      0.512      0.609      -0.041       0.070\n",
      "OTU_24870     -0.0322      0.042     -0.768      0.443      -0.115       0.050\n",
      "OTU_28808      0.0053      0.022      0.241      0.810      -0.038       0.049\n",
      "OTU_220       -0.0053      0.024     -0.221      0.825      -0.052       0.042\n",
      "OTU_25608     -0.0057      0.025     -0.233      0.816      -0.054       0.042\n",
      "OTU_4926      -0.0124      0.027     -0.457      0.648      -0.066       0.041\n",
      "OTU_21934      0.0142      0.029      0.489      0.625      -0.043       0.071\n",
      "OTU_3874       0.0249      0.028      0.900      0.369      -0.029       0.079\n",
      "OTU_112        0.0061      0.024      0.250      0.802      -0.042       0.054\n",
      "OTU_476       -0.0038      0.014     -0.267      0.789      -0.032       0.024\n",
      "OTU_252        0.0070      0.024      0.286      0.775      -0.041       0.055\n",
      "OTU_12153      0.0037      0.012      0.310      0.756      -0.020       0.027\n",
      "OTU_70         0.0110      0.028      0.389      0.697      -0.044       0.066\n",
      "OTU_6461       0.0083      0.020      0.406      0.685      -0.032       0.048\n",
      "OTU_806       -0.0069      0.028     -0.245      0.807      -0.062       0.048\n",
      "OTU_273        0.0050      0.030      0.168      0.867      -0.053       0.063\n",
      "OTU_15777     -0.0238      0.031     -0.771      0.441      -0.085       0.037\n",
      "OTU_27573      0.0058      0.025      0.237      0.813      -0.042       0.054\n",
      "OTU_8358      -0.0031      0.025     -0.124      0.902      -0.052       0.046\n",
      "OTU_201       -0.0017      0.025     -0.069      0.945      -0.052       0.048\n",
      "OTU_478       -0.0163      0.015     -1.117      0.265      -0.045       0.012\n",
      "OTU_148       -0.0025      0.027     -0.092      0.926      -0.056       0.051\n",
      "OTU_19203     -0.0070      0.028     -0.245      0.807      -0.063       0.049\n",
      "OTU_25463     -0.0009      0.029     -0.032      0.975      -0.059       0.057\n",
      "OTU_54        -0.0139      0.021     -0.645      0.519      -0.056       0.028\n",
      "OTU_233        0.0192      0.029      0.658      0.511      -0.038       0.076\n",
      "OTU_975        0.0013      0.019      0.068      0.946      -0.035       0.038\n",
      "OTU_22993     -0.0236      0.030     -0.782      0.434      -0.083       0.036\n",
      "OTU_130        0.0303      0.031      0.963      0.336      -0.032       0.092\n",
      "OTU_25015      0.0070      0.021      0.330      0.742      -0.034       0.048\n",
      "OTU_12021     -0.0249      0.028     -0.906      0.365      -0.079       0.029\n",
      "OTU_458       -0.0071      0.028     -0.259      0.796      -0.061       0.047\n",
      "OTU_2542       0.0053      0.022      0.234      0.815      -0.039       0.049\n",
      "OTU_1179      -0.0082      0.017     -0.492      0.623      -0.041       0.025\n",
      "OTU_11799      0.0209      0.022      0.946      0.345      -0.023       0.064\n",
      "OTU_3745      -0.0182      0.029     -0.623      0.533      -0.076       0.039\n",
      "OTU_27771     -0.0120      0.030     -0.393      0.695      -0.072       0.048\n",
      "OTU_373        0.0077      0.024      0.317      0.751      -0.040       0.055\n",
      "OTU_3386      -0.0008      0.030     -0.026      0.979      -0.060       0.059\n",
      "OTU_73        -0.0058      0.031     -0.188      0.851      -0.067       0.055\n",
      "OTU_10236     -0.0144      0.027     -0.539      0.590      -0.067       0.038\n",
      "OTU_209       -0.0267      0.028     -0.939      0.348      -0.083       0.029\n",
      "OTU_257       -0.0052      0.028     -0.189      0.851      -0.060       0.049\n",
      "OTU_6190      -0.0093      0.027     -0.344      0.731      -0.063       0.044\n",
      "OTU_8115       0.0256      0.029      0.874      0.382      -0.032       0.083\n",
      "OTU_532        0.0030      0.011      0.285      0.776      -0.018       0.024\n",
      "OTU_20561     -0.0008      0.029     -0.026      0.979      -0.058       0.057\n",
      "OTU_268        0.0185      0.023      0.815      0.416      -0.026       0.063\n",
      "OTU_251       -0.0405      0.028     -1.464      0.144      -0.095       0.014\n",
      "OTU_20596     -0.0143      0.028     -0.511      0.610      -0.069       0.041\n",
      "OTU_917        0.0142      0.021      0.679      0.497      -0.027       0.055\n",
      "OTU_144       -0.0055      0.023     -0.236      0.814      -0.051       0.040\n",
      "OTU_2042      -0.0051      0.025     -0.205      0.838      -0.053       0.043\n",
      "OTU_10858     -0.0009      0.027     -0.033      0.974      -0.053       0.051\n",
      "OTU_3          0.0128      0.027      0.471      0.638      -0.041       0.066\n",
      "OTU_643       -0.0074      0.027     -0.272      0.786      -0.061       0.046\n",
      "OTU_56         0.0092      0.026      0.348      0.728      -0.043       0.061\n",
      "OTU_18308      0.0124      0.029      0.431      0.667      -0.044       0.069\n",
      "OTU_51         0.0091      0.037      0.245      0.807      -0.064       0.082\n",
      "OTU_25484      0.0108      0.029      0.369      0.712      -0.047       0.068\n",
      "OTU_28383     -0.0071      0.023     -0.306      0.759      -0.053       0.038\n",
      "OTU_206        0.0191      0.027      0.702      0.483      -0.034       0.073\n",
      "OTU_6457       0.0079      0.024      0.335      0.738      -0.039       0.055\n",
      "OTU_8228      -0.0062      0.023     -0.265      0.791      -0.052       0.040\n",
      "OTU_11218     -0.0133      0.029     -0.454      0.650      -0.071       0.044\n",
      "OTU_27586     -0.0030      0.037     -0.082      0.935      -0.075       0.069\n",
      "OTU_352        0.0166      0.027      0.605      0.545      -0.037       0.071\n",
      "OTU_27963      0.0228      0.026      0.873      0.383      -0.028       0.074\n",
      "OTU_184        0.0005      0.013      0.035      0.972      -0.025       0.026\n",
      "OTU_3166       0.0247      0.025      0.983      0.326      -0.025       0.074\n",
      "OTU_585       -0.0023      0.028     -0.081      0.936      -0.057       0.053\n",
      "OTU_24550     -0.0031      0.022     -0.140      0.888      -0.047       0.041\n",
      "OTU_28132     -0.0100      0.028     -0.351      0.725      -0.066       0.046\n",
      "OTU_13075      0.0031      0.027      0.113      0.910      -0.050       0.056\n",
      "OTU_2628       0.0080      0.022      0.357      0.721      -0.036       0.052\n",
      "OTU_163       -0.0024      0.028     -0.085      0.933      -0.058       0.053\n",
      "OTU_3032       0.0005      0.023      0.021      0.983      -0.044       0.045\n",
      "OTU_21876      0.0003      0.013      0.022      0.982      -0.025       0.026\n",
      "OTU_242        0.0142      0.031      0.457      0.648      -0.047       0.075\n",
      "OTU_522        0.0171      0.023      0.737      0.461      -0.029       0.063\n",
      "OTU_12854      0.0254      0.026      0.992      0.321      -0.025       0.076\n",
      "OTU_4289      -0.0062      0.028     -0.222      0.824      -0.061       0.049\n",
      "OTU_17532     -0.0222      0.026     -0.840      0.401      -0.074       0.030\n",
      "OTU_26564     -0.0173      0.029     -0.588      0.557      -0.075       0.040\n",
      "OTU_14        -0.0177      0.031     -0.579      0.563      -0.078       0.042\n",
      "OTU_16392      0.0227      0.029      0.782      0.435      -0.034       0.080\n",
      "OTU_52         0.0042      0.025      0.170      0.865      -0.045       0.053\n",
      "OTU_21573      0.0323      0.029      1.100      0.272      -0.025       0.090\n",
      "OTU_1222       0.0063      0.027      0.232      0.817      -0.047       0.060\n",
      "OTU_23917      0.0068      0.025      0.274      0.784      -0.042       0.056\n",
      "OTU_27519      0.0113      0.028      0.405      0.686      -0.043       0.066\n",
      "OTU_9821       0.0225      0.026      0.868      0.386      -0.028       0.073\n",
      "OTU_350       -0.0303      0.024     -1.274      0.203      -0.077       0.016\n",
      "OTU_2641       0.0030      0.029      0.104      0.917      -0.054       0.060\n",
      "OTU_798        0.0021      0.029      0.074      0.941      -0.054       0.059\n",
      "OTU_221       -0.0202      0.027     -0.747      0.456      -0.073       0.033\n",
      "OTU_15216     -0.0168      0.025     -0.673      0.501      -0.066       0.032\n",
      "OTU_229       -0.0162      0.028     -0.582      0.561      -0.071       0.038\n",
      "OTU_25394      0.0020      0.026      0.077      0.939      -0.048       0.052\n",
      "OTU_24873      0.0127      0.027      0.478      0.633      -0.040       0.065\n",
      "OTU_216        0.0030      0.027      0.110      0.912      -0.050       0.056\n",
      "OTU_2481       0.0009      0.028      0.033      0.974      -0.054       0.056\n",
      "OTU_2734      -0.0184      0.022     -0.818      0.414      -0.063       0.026\n",
      "OTU_2704       0.0306      0.027      1.147      0.252      -0.022       0.083\n",
      "OTU_303       -0.0240      0.023     -1.029      0.304      -0.070       0.022\n",
      "OTU_5528      -0.0282      0.028     -1.007      0.315      -0.083       0.027\n",
      "OTU_374        0.0253      0.030      0.847      0.397      -0.033       0.084\n",
      "OTU_185       -0.0067      0.029     -0.233      0.816      -0.063       0.050\n",
      "OTU_215        0.0087      0.025      0.352      0.725      -0.040       0.057\n",
      "OTU_2422      -0.0218      0.029     -0.748      0.455      -0.079       0.035\n",
      "OTU_87        -0.0114      0.027     -0.429      0.668      -0.064       0.041\n",
      "OTU_121        0.0126      0.025      0.502      0.616      -0.037       0.062\n",
      "OTU_28653     -0.0207      0.027     -0.754      0.451      -0.075       0.033\n",
      "OTU_1358      -0.0051      0.027     -0.189      0.851      -0.059       0.048\n",
      "OTU_25686     -0.0034      0.024     -0.143      0.887      -0.051       0.044\n",
      "OTU_17600      0.0326      0.034      0.967      0.334      -0.034       0.099\n",
      "OTU_409        0.0206      0.030      0.695      0.487      -0.038       0.079\n",
      "OTU_436       -0.0283      0.030     -0.954      0.341      -0.087       0.030\n",
      "OTU_26638     -0.0108      0.028     -0.386      0.700      -0.066       0.044\n",
      "OTU_119        0.0185      0.026      0.709      0.479      -0.033       0.070\n",
      "OTU_11212      0.0134      0.026      0.510      0.611      -0.038       0.065\n",
      "OTU_218        0.0215      0.024      0.914      0.361      -0.025       0.068\n",
      "OTU_1235      -0.0225      0.023     -0.994      0.321      -0.067       0.022\n",
      "OTU_126       -0.0243      0.026     -0.946      0.344      -0.075       0.026\n",
      "OTU_6105       0.0128      0.029      0.436      0.663      -0.045       0.071\n",
      "OTU_2516      -0.0164      0.030     -0.542      0.588      -0.076       0.043\n",
      "OTU_6204      -0.0139      0.027     -0.509      0.611      -0.068       0.040\n",
      "OTU_23581     -0.0041      0.030     -0.138      0.890      -0.062       0.054\n",
      "OTU_253       -0.0287      0.024     -1.176      0.240      -0.077       0.019\n",
      "OTU_10255      0.0158      0.026      0.612      0.541      -0.035       0.067\n",
      "OTU_60         0.0074      0.019      0.394      0.694      -0.030       0.044\n",
      "OTU_188       -0.0098      0.027     -0.363      0.717      -0.063       0.043\n",
      "OTU_17917      0.0443      0.032      1.392      0.164      -0.018       0.107\n",
      "OTU_28416     -0.0449      0.029     -1.572      0.117      -0.101       0.011\n",
      "OTU_200       -0.0440      0.029     -1.544      0.123      -0.100       0.012\n",
      "OTU_170       -0.0093      0.029     -0.318      0.751      -0.067       0.048\n",
      "OTU_27636     -0.0241      0.028     -0.861      0.390      -0.079       0.031\n",
      "OTU_6477      -0.0059      0.022     -0.269      0.788      -0.049       0.037\n",
      "OTU_27960     -0.0143      0.025     -0.569      0.570      -0.064       0.035\n",
      "OTU_2995      -0.0109      0.019     -0.580      0.562      -0.048       0.026\n",
      "OTU_17625      0.0386      0.030      1.277      0.202      -0.021       0.098\n",
      "OTU_0          0.0060      0.032      0.188      0.851      -0.057       0.069\n",
      "OTU_240       -0.0063      0.029     -0.218      0.827      -0.063       0.051\n",
      "OTU_364        0.0064      0.023      0.284      0.777      -0.038       0.051\n",
      "OTU_27620     -0.0281      0.042     -0.666      0.506      -0.111       0.055\n",
      "OTU_617       -0.0013      0.019     -0.070      0.944      -0.038       0.035\n",
      "OTU_14661     -0.0057      0.029     -0.198      0.843      -0.062       0.051\n",
      "OTU_25514      0.0006      0.018      0.035      0.972      -0.035       0.036\n",
      "OTU_23468     -0.0050      0.028     -0.182      0.856      -0.060       0.049\n",
      "OTU_24877     -0.0350      0.031     -1.126      0.261      -0.096       0.026\n",
      "OTU_5415       0.0253      0.027      0.930      0.353      -0.028       0.079\n",
      "OTU_14036      0.0200      0.024      0.843      0.400      -0.027       0.067\n",
      "OTU_3690       0.0263      0.030      0.865      0.388      -0.033       0.086\n",
      "OTU_5328       0.0203      0.025      0.824      0.411      -0.028       0.069\n",
      "OTU_20590      0.0048      0.028      0.174      0.862      -0.049       0.059\n",
      "==============================================================================\n",
      "Omnibus:                        9.302   Durbin-Watson:                   1.571\n",
      "Prob(Omnibus):                  0.010   Jarque-Bera (JB):               14.462\n",
      "Skew:                           0.030   Prob(JB):                     0.000724\n",
      "Kurtosis:                       3.712   Cond. No.                         544.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.075\n",
      "Model:                            OLS   Adj. R-squared:                  0.029\n",
      "Method:                 Least Squares   F-statistic:                     1.644\n",
      "Date:                Tue, 14 May 2024   Prob (F-statistic):             0.0150\n",
      "Time:                        19:37:12   Log-Likelihood:                -194.19\n",
      "No. Observations:                 680   AIC:                             454.4\n",
      "Df Residuals:                     647   BIC:                             603.6\n",
      "Df Model:                          32                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.9412      0.077     38.140      0.000       2.790       3.093\n",
      "snp3          -0.0602      0.021     -2.933      0.003      -0.100      -0.020\n",
      "snp6          -0.0859      0.014     -6.135      0.000      -0.113      -0.058\n",
      "snp7          -0.0925      0.026     -3.498      0.001      -0.144      -0.041\n",
      "OTU_25881      0.0008      0.018      0.043      0.966      -0.034       0.036\n",
      "OTU_27598     -0.0012      0.018     -0.064      0.949      -0.037       0.035\n",
      "OTU_4067      -0.0010      0.020     -0.048      0.961      -0.040       0.038\n",
      "OTU_27573      0.0001      0.017      0.006      0.995      -0.033       0.033\n",
      "OTU_478       -0.0014      0.009     -0.148      0.882      -0.020       0.017\n",
      "OTU_54        -0.0008      0.010     -0.077      0.938      -0.021       0.019\n",
      "OTU_209       -0.0063      0.019     -0.337      0.736      -0.043       0.031\n",
      "OTU_21876     -0.0022      0.009     -0.237      0.812      -0.020       0.016\n",
      "OTU_4289       0.0006      0.018      0.031      0.975      -0.034       0.036\n",
      "OTU_17532      0.0004      0.018      0.021      0.983      -0.035       0.036\n",
      "OTU_350       -0.0022      0.011     -0.194      0.846      -0.025       0.020\n",
      "OTU_15216     -0.0067      0.016     -0.407      0.684      -0.039       0.025\n",
      "OTU_303        0.0005      0.014      0.035      0.972      -0.027       0.028\n",
      "OTU_5528      -0.0025      0.019     -0.130      0.897      -0.040       0.035\n",
      "OTU_2422      -0.0115      0.020     -0.571      0.568      -0.051       0.028\n",
      "OTU_28653     -0.0049      0.018     -0.270      0.787      -0.041       0.031\n",
      "OTU_436       -0.0006      0.021     -0.029      0.977      -0.042       0.041\n",
      "OTU_1235      -0.0117      0.013     -0.938      0.349      -0.036       0.013\n",
      "OTU_126       -0.0002      0.017     -0.009      0.993      -0.034       0.034\n",
      "OTU_2516      -0.0007      0.020     -0.035      0.972      -0.040       0.039\n",
      "OTU_253       -0.0003      0.015     -0.017      0.986      -0.030       0.030\n",
      "OTU_28416     -0.0051      0.018     -0.279      0.780      -0.041       0.031\n",
      "OTU_200       -0.0034      0.019     -0.180      0.857      -0.040       0.034\n",
      "OTU_27636     -0.0035      0.017     -0.203      0.839      -0.038       0.031\n",
      "OTU_27960     -0.0032      0.017     -0.186      0.853      -0.037       0.031\n",
      "OTU_617       -0.0010      0.013     -0.076      0.939      -0.026       0.024\n",
      "OTU_14661     -0.0081      0.018     -0.448      0.655      -0.044       0.028\n",
      "OTU_23468     -0.0070      0.017     -0.416      0.677      -0.040       0.026\n",
      "OTU_24877     -0.0074      0.022     -0.340      0.734      -0.050       0.036\n",
      "==============================================================================\n",
      "Omnibus:                        5.262   Durbin-Watson:                   1.505\n",
      "Prob(Omnibus):                  0.072   Jarque-Bera (JB):                6.782\n",
      "Skew:                           0.022   Prob(JB):                       0.0337\n",
      "Kurtosis:                       3.487   Cond. No.                         62.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "TSLWm3： X_selected shape: (680, 34)\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.097\n",
      "Model:                            OLS   Adj. R-squared:                  0.051\n",
      "Method:                 Least Squares   F-statistic:                     2.104\n",
      "Date:                Tue, 14 May 2024   Prob (F-statistic):           0.000367\n",
      "Time:                        19:37:15   Log-Likelihood:                -186.06\n",
      "No. Observations:                 680   AIC:                             440.1\n",
      "Df Residuals:                     646   BIC:                             593.9\n",
      "Df Model:                          33                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              2.8513      0.072     39.810      0.000       2.711       2.992\n",
      "snp6              -0.0143      0.046     -0.312      0.755      -0.104       0.076\n",
      "OTU_54             0.0003      0.006      0.049      0.961      -0.012       0.013\n",
      "OTU_209           -0.0060      0.017     -0.347      0.728      -0.040       0.028\n",
      "OTU_21876         -0.0014      0.009     -0.162      0.871      -0.018       0.016\n",
      "OTU_350        -9.053e-05      0.011     -0.008      0.993      -0.022       0.022\n",
      "OTU_303         1.179e-05      0.014      0.001      0.999      -0.027       0.027\n",
      "OTU_28653          0.0004      0.017      0.022      0.982      -0.033       0.033\n",
      "OTU_1235          -0.0070      0.015     -0.475      0.635      -0.036       0.022\n",
      "OTU_28416         -0.0067      0.018     -0.383      0.702      -0.041       0.028\n",
      "OTU_200           -0.0037      0.017     -0.220      0.826      -0.037       0.030\n",
      "OTU_27960          0.0003      0.016      0.016      0.987      -0.032       0.032\n",
      "OTU_14661         -0.0049      0.018     -0.275      0.783      -0.040       0.030\n",
      "snp3:OTU_25881    -0.0024      0.016     -0.146      0.884      -0.035       0.030\n",
      "snp3:OTU_15216    -0.0268      0.021     -1.285      0.199      -0.068       0.014\n",
      "snp3:OTU_23468    -0.0151      0.016     -0.957      0.339      -0.046       0.016\n",
      "snp3:OTU_24877    -0.0019      0.030     -0.062      0.950      -0.061       0.057\n",
      "snp6:OTU_4067     -0.0057      0.013     -0.438      0.662      -0.031       0.020\n",
      "snp6:OTU_478      -0.0026      0.006     -0.423      0.672      -0.015       0.009\n",
      "snp6:OTU_4289     -0.0048      0.012     -0.411      0.681      -0.028       0.018\n",
      "snp6:OTU_5528     -0.0082      0.013     -0.648      0.518      -0.033       0.017\n",
      "snp6:OTU_2422     -0.0122      0.013     -0.915      0.361      -0.039       0.014\n",
      "snp6:OTU_436      -0.0065      0.014     -0.459      0.647      -0.035       0.021\n",
      "snp6:OTU_1235     -0.0041      0.010     -0.431      0.667      -0.023       0.015\n",
      "snp6:OTU_2516      0.0002      0.012      0.019      0.985      -0.023       0.023\n",
      "snp6:OTU_617      -0.0046      0.008     -0.601      0.548      -0.020       0.010\n",
      "snp6:OTU_23468 -3.578e-06      0.011     -0.000      1.000      -0.022       0.022\n",
      "snp6:OTU_24877    -0.0101      0.014     -0.706      0.480      -0.038       0.018\n",
      "snp7:OTU_27573    -0.0309      0.029     -1.053      0.293      -0.089       0.027\n",
      "snp7:OTU_350      -0.0091      0.016     -0.553      0.581      -0.041       0.023\n",
      "snp7:OTU_15216    -0.0066      0.029     -0.228      0.819      -0.063       0.050\n",
      "snp7:OTU_5528     -0.0138      0.038     -0.363      0.716      -0.088       0.061\n",
      "snp7:OTU_126      -0.0155      0.025     -0.625      0.532      -0.064       0.033\n",
      "snp7:OTU_27636    -0.0030      0.023     -0.131      0.896      -0.048       0.042\n",
      "==============================================================================\n",
      "Omnibus:                        4.472   Durbin-Watson:                   1.512\n",
      "Prob(Omnibus):                  0.107   Jarque-Bera (JB):                5.522\n",
      "Skew:                           0.011   Prob(JB):                       0.0632\n",
      "Kurtosis:                       3.441   Cond. No.                         63.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.097\n",
      "Model:                            OLS   Adj. R-squared:                  0.051\n",
      "Method:                 Least Squares   F-statistic:                     2.104\n",
      "Date:                Tue, 14 May 2024   Prob (F-statistic):           0.000367\n",
      "Time:                        19:37:15   Log-Likelihood:                -186.06\n",
      "No. Observations:                 680   AIC:                             440.1\n",
      "Df Residuals:                     646   BIC:                             593.9\n",
      "Df Model:                          33                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              2.8513      0.072     39.810      0.000       2.711       2.992\n",
      "snp6              -0.0143      0.046     -0.312      0.755      -0.104       0.076\n",
      "OTU_54             0.0003      0.006      0.049      0.961      -0.012       0.013\n",
      "OTU_209           -0.0060      0.017     -0.347      0.728      -0.040       0.028\n",
      "OTU_21876         -0.0014      0.009     -0.162      0.871      -0.018       0.016\n",
      "OTU_350        -9.053e-05      0.011     -0.008      0.993      -0.022       0.022\n",
      "OTU_303         1.179e-05      0.014      0.001      0.999      -0.027       0.027\n",
      "OTU_28653          0.0004      0.017      0.022      0.982      -0.033       0.033\n",
      "OTU_1235          -0.0070      0.015     -0.475      0.635      -0.036       0.022\n",
      "OTU_28416         -0.0067      0.018     -0.383      0.702      -0.041       0.028\n",
      "OTU_200           -0.0037      0.017     -0.220      0.826      -0.037       0.030\n",
      "OTU_27960          0.0003      0.016      0.016      0.987      -0.032       0.032\n",
      "OTU_14661         -0.0049      0.018     -0.275      0.783      -0.040       0.030\n",
      "snp3:OTU_25881    -0.0024      0.016     -0.146      0.884      -0.035       0.030\n",
      "snp3:OTU_15216    -0.0268      0.021     -1.285      0.199      -0.068       0.014\n",
      "snp3:OTU_23468    -0.0151      0.016     -0.957      0.339      -0.046       0.016\n",
      "snp3:OTU_24877    -0.0019      0.030     -0.062      0.950      -0.061       0.057\n",
      "snp6:OTU_4067     -0.0057      0.013     -0.438      0.662      -0.031       0.020\n",
      "snp6:OTU_478      -0.0026      0.006     -0.423      0.672      -0.015       0.009\n",
      "snp6:OTU_4289     -0.0048      0.012     -0.411      0.681      -0.028       0.018\n",
      "snp6:OTU_5528     -0.0082      0.013     -0.648      0.518      -0.033       0.017\n",
      "snp6:OTU_2422     -0.0122      0.013     -0.915      0.361      -0.039       0.014\n",
      "snp6:OTU_436      -0.0065      0.014     -0.459      0.647      -0.035       0.021\n",
      "snp6:OTU_1235     -0.0041      0.010     -0.431      0.667      -0.023       0.015\n",
      "snp6:OTU_2516      0.0002      0.012      0.019      0.985      -0.023       0.023\n",
      "snp6:OTU_617      -0.0046      0.008     -0.601      0.548      -0.020       0.010\n",
      "snp6:OTU_23468 -3.578e-06      0.011     -0.000      1.000      -0.022       0.022\n",
      "snp6:OTU_24877    -0.0101      0.014     -0.706      0.480      -0.038       0.018\n",
      "snp7:OTU_27573    -0.0309      0.029     -1.053      0.293      -0.089       0.027\n",
      "snp7:OTU_350      -0.0091      0.016     -0.553      0.581      -0.041       0.023\n",
      "snp7:OTU_15216    -0.0066      0.029     -0.228      0.819      -0.063       0.050\n",
      "snp7:OTU_5528     -0.0138      0.038     -0.363      0.716      -0.088       0.061\n",
      "snp7:OTU_126      -0.0155      0.025     -0.625      0.532      -0.064       0.033\n",
      "snp7:OTU_27636    -0.0030      0.023     -0.131      0.896      -0.048       0.042\n",
      "==============================================================================\n",
      "Omnibus:                        4.472   Durbin-Watson:                   1.512\n",
      "Prob(Omnibus):                  0.107   Jarque-Bera (JB):                5.522\n",
      "Skew:                           0.011   Prob(JB):                       0.0632\n",
      "Kurtosis:                       3.441   Cond. No.                         63.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "TSLWm4： X_selected shape: (680, 31)\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.165\n",
      "Model:                            OLS   Adj. R-squared:                  0.127\n",
      "Method:                 Least Squares   F-statistic:                     4.283\n",
      "Date:                Tue, 14 May 2024   Prob (F-statistic):           1.13e-12\n",
      "Time:                        19:37:15   Log-Likelihood:                -159.35\n",
      "No. Observations:                 680   AIC:                             380.7\n",
      "Df Residuals:                     649   BIC:                             520.9\n",
      "Df Model:                          30                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              2.8381      0.052     55.104      0.000       2.737       2.939\n",
      "snp6              -0.0129      0.037     -0.354      0.724      -0.085       0.059\n",
      "OTU_54            -0.0003      0.006     -0.057      0.954      -0.012       0.011\n",
      "OTU_209           -0.0037      0.016     -0.223      0.824      -0.036       0.029\n",
      "OTU_350           -0.0035      0.010     -0.359      0.720      -0.023       0.016\n",
      "OTU_303           -0.0009      0.013     -0.069      0.945      -0.027       0.025\n",
      "OTU_28416         -0.0053      0.017     -0.323      0.747      -0.038       0.027\n",
      "OTU_200            0.0001      0.014      0.007      0.994      -0.027       0.027\n",
      "OTU_14661         -0.0076      0.017     -0.448      0.655      -0.041       0.026\n",
      "snp3:OTU_25881    -0.0063      0.016     -0.402      0.688      -0.037       0.024\n",
      "snp3:OTU_15216    -0.0234      0.020     -1.184      0.237      -0.062       0.015\n",
      "snp3:OTU_23468    -0.0151      0.015     -1.000      0.317      -0.045       0.015\n",
      "snp3:OTU_24877    -0.0072      0.029     -0.251      0.802      -0.064       0.049\n",
      "snp6:OTU_4067     -0.0028      0.012     -0.225      0.822      -0.027       0.022\n",
      "snp6:OTU_5528     -0.0104      0.012     -0.881      0.379      -0.034       0.013\n",
      "snp6:OTU_2422     -0.0175      0.013     -1.388      0.166      -0.042       0.007\n",
      "snp6:OTU_436      -0.0040      0.013     -0.297      0.766      -0.030       0.022\n",
      "snp6:OTU_1235     -0.0064      0.006     -1.007      0.314      -0.019       0.006\n",
      "snp6:OTU_617      -0.0061      0.006     -0.976      0.329      -0.018       0.006\n",
      "snp6:OTU_23468    -0.0005      0.010     -0.053      0.958      -0.020       0.019\n",
      "snp6:OTU_24877    -0.0090      0.013     -0.700      0.484      -0.034       0.016\n",
      "snp7:OTU_27573    -0.0270      0.025     -1.088      0.277      -0.076       0.022\n",
      "snp7:OTU_350      -0.0066      0.015     -0.428      0.669      -0.037       0.024\n",
      "snp7:OTU_15216    -0.0102      0.028     -0.370      0.711      -0.064       0.044\n",
      "snp7:OTU_5528     -0.0255      0.036     -0.711      0.477      -0.096       0.045\n",
      "snp7:OTU_126      -0.0155      0.022     -0.696      0.487      -0.059       0.028\n",
      "PC2               -2.0626      0.364     -5.672      0.000      -2.777      -1.349\n",
      "PC5               -0.8818      0.402     -2.196      0.028      -1.670      -0.093\n",
      "PC6               -1.4111      0.356     -3.966      0.000      -2.110      -0.712\n",
      "PC9               -0.1553      0.361     -0.430      0.667      -0.864       0.554\n",
      "PC10              -0.0113      0.354     -0.032      0.975      -0.707       0.684\n",
      "==============================================================================\n",
      "Omnibus:                        6.721   Durbin-Watson:                   1.582\n",
      "Prob(Omnibus):                  0.035   Jarque-Bera (JB):                9.400\n",
      "Skew:                           0.007   Prob(JB):                      0.00910\n",
      "Kurtosis:                       3.576   Cond. No.                         305.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   TSLW   R-squared:                       0.165\n",
      "Model:                            OLS   Adj. R-squared:                  0.127\n",
      "Method:                 Least Squares   F-statistic:                     4.283\n",
      "Date:                Tue, 14 May 2024   Prob (F-statistic):           1.13e-12\n",
      "Time:                        19:37:15   Log-Likelihood:                -159.35\n",
      "No. Observations:                 680   AIC:                             380.7\n",
      "Df Residuals:                     649   BIC:                             520.9\n",
      "Df Model:                          30                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              2.8381      0.052     55.104      0.000       2.737       2.939\n",
      "snp6              -0.0129      0.037     -0.354      0.724      -0.085       0.059\n",
      "OTU_54            -0.0003      0.006     -0.057      0.954      -0.012       0.011\n",
      "OTU_209           -0.0037      0.016     -0.223      0.824      -0.036       0.029\n",
      "OTU_350           -0.0035      0.010     -0.359      0.720      -0.023       0.016\n",
      "OTU_303           -0.0009      0.013     -0.069      0.945      -0.027       0.025\n",
      "OTU_28416         -0.0053      0.017     -0.323      0.747      -0.038       0.027\n",
      "OTU_200            0.0001      0.014      0.007      0.994      -0.027       0.027\n",
      "OTU_14661         -0.0076      0.017     -0.448      0.655      -0.041       0.026\n",
      "snp3:OTU_25881    -0.0063      0.016     -0.402      0.688      -0.037       0.024\n",
      "snp3:OTU_15216    -0.0234      0.020     -1.184      0.237      -0.062       0.015\n",
      "snp3:OTU_23468    -0.0151      0.015     -1.000      0.317      -0.045       0.015\n",
      "snp3:OTU_24877    -0.0072      0.029     -0.251      0.802      -0.064       0.049\n",
      "snp6:OTU_4067     -0.0028      0.012     -0.225      0.822      -0.027       0.022\n",
      "snp6:OTU_5528     -0.0104      0.012     -0.881      0.379      -0.034       0.013\n",
      "snp6:OTU_2422     -0.0175      0.013     -1.388      0.166      -0.042       0.007\n",
      "snp6:OTU_436      -0.0040      0.013     -0.297      0.766      -0.030       0.022\n",
      "snp6:OTU_1235     -0.0064      0.006     -1.007      0.314      -0.019       0.006\n",
      "snp6:OTU_617      -0.0061      0.006     -0.976      0.329      -0.018       0.006\n",
      "snp6:OTU_23468    -0.0005      0.010     -0.053      0.958      -0.020       0.019\n",
      "snp6:OTU_24877    -0.0090      0.013     -0.700      0.484      -0.034       0.016\n",
      "snp7:OTU_27573    -0.0270      0.025     -1.088      0.277      -0.076       0.022\n",
      "snp7:OTU_350      -0.0066      0.015     -0.428      0.669      -0.037       0.024\n",
      "snp7:OTU_15216    -0.0102      0.028     -0.370      0.711      -0.064       0.044\n",
      "snp7:OTU_5528     -0.0255      0.036     -0.711      0.477      -0.096       0.045\n",
      "snp7:OTU_126      -0.0155      0.022     -0.696      0.487      -0.059       0.028\n",
      "PC2               -2.0626      0.364     -5.672      0.000      -2.777      -1.349\n",
      "PC5               -0.8818      0.402     -2.196      0.028      -1.670      -0.093\n",
      "PC6               -1.4111      0.356     -3.966      0.000      -2.110      -0.712\n",
      "PC9               -0.1553      0.361     -0.430      0.667      -0.864       0.554\n",
      "PC10              -0.0113      0.354     -0.032      0.975      -0.707       0.684\n",
      "==============================================================================\n",
      "Omnibus:                        6.721   Durbin-Watson:                   1.582\n",
      "Prob(Omnibus):                  0.035   Jarque-Bera (JB):                9.400\n",
      "Skew:                           0.007   Prob(JB):                      0.00910\n",
      "Kurtosis:                       3.576   Cond. No.                         305.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## 再次进行向后逐步回归\n",
    "selected_features = backward_elimination(X_selected, y)\n",
    "X_selected = sm.add_constant(X_selected[selected_features])\n",
    "TSLWm = sm.OLS(y, X_selected).fit()\n",
    "print(TSLWm.summary())\n",
    "\n",
    "# 创建snp和OTU交互并更新模型\n",
    "# 提取 snp 和 OTU 变量名\n",
    "name_snp = [var for var in selected_features if re.match(r\"^snp\", var)]\n",
    "name_otu = [var for var in selected_features if re.match(r\"OTU\", var)]\n",
    "\n",
    "interaction_terms = pd.DataFrame()\n",
    "for snp in name_snp:\n",
    "    for otu in name_otu:\n",
    "        interaction_terms[f\"{snp}:{otu}\"] = data[snp] * data[otu]\n",
    "\n",
    "X_selected = pd.concat([X_selected, interaction_terms], axis=1)\n",
    "selected_features = backward_elimination(X_selected, y)\n",
    "X_selected = sm.add_constant(X_selected[selected_features])\n",
    "TSLWm3 = sm.OLS(y, X_selected).fit()\n",
    "print(f\"TSLWm3： X_selected shape: {X_selected.shape}\\n\", TSLWm3.summary())\n",
    "\n",
    "# 再次进行向后逐步回归\n",
    "selected_features = backward_elimination(X_selected, y)\n",
    "X_selected = sm.add_constant(X_selected[selected_features])\n",
    "TSLWm = sm.OLS(y, X_selected).fit()\n",
    "print(TSLWm.summary())\n",
    "\n",
    "# 添加 PC 变量并更新模型\n",
    "X_selected = pd.concat([X_selected, data[pc_columns]], axis=1)\n",
    "selected_features = backward_elimination(X_selected, y)\n",
    "X_selected = sm.add_constant(X_selected[selected_features])\n",
    "TSLWm4 = sm.OLS(y, X_selected).fit()\n",
    "print(f\"TSLWm4： X_selected shape: {X_selected.shape}\\n\", TSLWm4.summary())\n",
    "\n",
    "# 再次进行向后逐步回归\n",
    "selected_features = backward_elimination(X_selected, y)\n",
    "X_selected = sm.add_constant(X_selected[selected_features])\n",
    "TSLWm = sm.OLS(y, X_selected).fit()\n",
    "print(TSLWm.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "     snp1  snp2  snp3  snp4  snp5  snp6  snp7  snp8  snp9  OTU_7084  ...  \\\n0     0.0   2.0   0.0   0.0   0.0   0.0   2.0   0.0   2.0    1.6981  ...   \n1     2.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    1.9616  ...   \n2     0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    1.2965  ...   \n3     0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    2.7451  ...   \n5     0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0    1.5971  ...   \n..    ...   ...   ...   ...   ...   ...   ...   ...   ...       ...  ...   \n821   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    2.2451  ...   \n822   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0    2.4170  ...   \n823   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    1.6844  ...   \n824   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    1.3049  ...   \n826   0.0   2.0   2.0   0.0   0.0   0.0   2.0   0.0   2.0    2.4679  ...   \n\n     OTU_617  OTU_14661  OTU_25514  OTU_23468  OTU_24877  OTU_5415  OTU_14036  \\\n0     1.6981    0.00000     1.9282     1.4241    1.08570   0.00000    1.69810   \n1     1.4083    0.86958     4.9820     2.7634    2.36050   0.00000    1.16390   \n2     1.7770    0.57089     1.7770     1.5567    0.57089   0.00000    0.57089   \n3     3.4132    0.90887     3.4132     1.6753    0.52485   0.52485    1.46210   \n5     3.4759    1.33280     2.3365     1.3328    1.00910   0.00000    1.59710   \n..       ...        ...        ...        ...        ...       ...        ...   \n821   4.8082    2.36630     3.4562     3.0843    0.87283   1.62210    1.41280   \n822   2.9407    1.22380     2.8094     4.1722    2.11730   2.41700    1.73870   \n823   3.0670    2.22960     2.7874     1.6844    0.79743   0.79743    1.30800   \n824   0.0000    1.30490     0.0000     2.7829    1.30490   1.30490    1.97860   \n826   1.9576    1.61360     4.6379     2.6682    0.86716   3.07320    1.16100   \n\n     OTU_3690  OTU_5328  OTU_20590  \n0      2.1266    2.3011     2.1266  \n1      3.6048    2.6727     2.3605  \n2      1.7770    2.6644     2.1369  \n3      2.1732    1.8611     3.1535  \n5      1.5971    2.9226     1.8203  \n..        ...       ...        ...  \n821    3.9966    2.8549     2.6788  \n822    2.5870    3.1176     4.1452  \n823    3.5934    0.0000     1.3080  \n824    2.4361    1.3049     3.0623  \n826    3.6481    2.9246     3.0008  \n\n[680 rows x 209 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>snp1</th>\n      <th>snp2</th>\n      <th>snp3</th>\n      <th>snp4</th>\n      <th>snp5</th>\n      <th>snp6</th>\n      <th>snp7</th>\n      <th>snp8</th>\n      <th>snp9</th>\n      <th>OTU_7084</th>\n      <th>...</th>\n      <th>OTU_617</th>\n      <th>OTU_14661</th>\n      <th>OTU_25514</th>\n      <th>OTU_23468</th>\n      <th>OTU_24877</th>\n      <th>OTU_5415</th>\n      <th>OTU_14036</th>\n      <th>OTU_3690</th>\n      <th>OTU_5328</th>\n      <th>OTU_20590</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.6981</td>\n      <td>...</td>\n      <td>1.6981</td>\n      <td>0.00000</td>\n      <td>1.9282</td>\n      <td>1.4241</td>\n      <td>1.08570</td>\n      <td>0.00000</td>\n      <td>1.69810</td>\n      <td>2.1266</td>\n      <td>2.3011</td>\n      <td>2.1266</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.9616</td>\n      <td>...</td>\n      <td>1.4083</td>\n      <td>0.86958</td>\n      <td>4.9820</td>\n      <td>2.7634</td>\n      <td>2.36050</td>\n      <td>0.00000</td>\n      <td>1.16390</td>\n      <td>3.6048</td>\n      <td>2.6727</td>\n      <td>2.3605</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.2965</td>\n      <td>...</td>\n      <td>1.7770</td>\n      <td>0.57089</td>\n      <td>1.7770</td>\n      <td>1.5567</td>\n      <td>0.57089</td>\n      <td>0.00000</td>\n      <td>0.57089</td>\n      <td>1.7770</td>\n      <td>2.6644</td>\n      <td>2.1369</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.7451</td>\n      <td>...</td>\n      <td>3.4132</td>\n      <td>0.90887</td>\n      <td>3.4132</td>\n      <td>1.6753</td>\n      <td>0.52485</td>\n      <td>0.52485</td>\n      <td>1.46210</td>\n      <td>2.1732</td>\n      <td>1.8611</td>\n      <td>3.1535</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.5971</td>\n      <td>...</td>\n      <td>3.4759</td>\n      <td>1.33280</td>\n      <td>2.3365</td>\n      <td>1.3328</td>\n      <td>1.00910</td>\n      <td>0.00000</td>\n      <td>1.59710</td>\n      <td>1.5971</td>\n      <td>2.9226</td>\n      <td>1.8203</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>821</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.2451</td>\n      <td>...</td>\n      <td>4.8082</td>\n      <td>2.36630</td>\n      <td>3.4562</td>\n      <td>3.0843</td>\n      <td>0.87283</td>\n      <td>1.62210</td>\n      <td>1.41280</td>\n      <td>3.9966</td>\n      <td>2.8549</td>\n      <td>2.6788</td>\n    </tr>\n    <tr>\n      <th>822</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.4170</td>\n      <td>...</td>\n      <td>2.9407</td>\n      <td>1.22380</td>\n      <td>2.8094</td>\n      <td>4.1722</td>\n      <td>2.11730</td>\n      <td>2.41700</td>\n      <td>1.73870</td>\n      <td>2.5870</td>\n      <td>3.1176</td>\n      <td>4.1452</td>\n    </tr>\n    <tr>\n      <th>823</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.6844</td>\n      <td>...</td>\n      <td>3.0670</td>\n      <td>2.22960</td>\n      <td>2.7874</td>\n      <td>1.6844</td>\n      <td>0.79743</td>\n      <td>0.79743</td>\n      <td>1.30800</td>\n      <td>3.5934</td>\n      <td>0.0000</td>\n      <td>1.3080</td>\n    </tr>\n    <tr>\n      <th>824</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.3049</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>1.30490</td>\n      <td>0.0000</td>\n      <td>2.7829</td>\n      <td>1.30490</td>\n      <td>1.30490</td>\n      <td>1.97860</td>\n      <td>2.4361</td>\n      <td>1.3049</td>\n      <td>3.0623</td>\n    </tr>\n    <tr>\n      <th>826</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.4679</td>\n      <td>...</td>\n      <td>1.9576</td>\n      <td>1.61360</td>\n      <td>4.6379</td>\n      <td>2.6682</td>\n      <td>0.86716</td>\n      <td>3.07320</td>\n      <td>1.16100</td>\n      <td>3.6481</td>\n      <td>2.9246</td>\n      <td>3.0008</td>\n    </tr>\n  </tbody>\n</table>\n<p>680 rows × 209 columns</p>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support: [ True False False False False False False False False]\n",
      "Ranking: [1 2 7 6 9 3 5 4 8]\n",
      "Coefficients: [0.28137436]\n",
      "Intercept: 2.6698467571644042\n",
      "Updated Coefficients: [ 3.77634893e-01  2.43741909e-01 -6.63016104e-02 -2.68418287e+11\n",
      "  2.68418287e+11  1.57867615e-01 -1.05939628e-01  1.05804976e-01\n",
      "  3.68219916e-02 -2.10447311e-02  1.03416443e-02  4.91333008e-03\n",
      " -3.24249268e-04 -1.12438202e-03 -6.11305237e-03  1.51290894e-02\n",
      " -8.68034363e-03  1.28974915e-02  6.02722168e-03 -1.44548416e-02\n",
      "  2.46772766e-02 -1.97582245e-02  2.75802612e-02 -2.21309662e-02\n",
      "  1.21634007e-02  5.46050072e-03  4.19812202e-02 -1.57775879e-02\n",
      " -1.58023834e-02 -1.15966797e-03 -9.66072083e-03  1.66101456e-02\n",
      " -8.69083405e-03  2.93064117e-02  8.89587402e-03 -1.45354271e-02\n",
      "  8.86154175e-03 -1.42426491e-02 -2.81825066e-02  1.33781433e-02\n",
      "  2.15778351e-02  2.63824463e-02  1.68037415e-02 -1.61170959e-04\n",
      "  5.56182861e-03  1.20637417e-02 -3.04527283e-02 -4.52041626e-03\n",
      " -1.37825012e-02 -6.18743896e-03 -2.35290527e-02 -6.14929199e-03\n",
      "  2.58660316e-03 -4.86526489e-02  7.74002075e-03  1.94034576e-02\n",
      " -4.42504883e-04 -3.09524536e-02 -6.36672974e-03  1.64098740e-02\n",
      "  1.41601562e-02  1.44004822e-02  1.57279968e-02  1.30920410e-02\n",
      "  8.54492188e-03 -1.52587891e-05 -2.37464905e-03 -9.05227661e-03\n",
      " -3.18002701e-03  5.28817177e-02 -7.93743134e-03 -2.68402100e-02\n",
      "  1.50756836e-02 -1.19857788e-02 -1.90124512e-02  7.95745850e-03\n",
      "  1.65882111e-02 -1.53083801e-02 -1.68457031e-02  4.36342955e-02\n",
      "  1.25656128e-02 -3.01437378e-02  3.64074707e-02 -1.40953064e-03\n",
      " -1.02348328e-02  9.76264477e-03 -4.33921814e-03 -3.53393555e-02\n",
      "  2.30560303e-02  6.59179688e-03 -3.63979340e-02  1.65348053e-02\n",
      "  1.76343918e-02 -3.94001007e-02 -4.99196053e-02 -4.81224060e-02\n",
      " -7.82966614e-04  2.06756592e-02  2.59590149e-02  1.71737671e-02\n",
      " -1.39396191e-02  2.95944214e-02 -8.44154358e-02  1.07471943e-02\n",
      "  2.71480083e-02  2.89916992e-04 -2.17247009e-03 -2.40364075e-02\n",
      " -1.07498169e-02 -1.95999146e-02 -6.48880005e-03  3.49578857e-02\n",
      "  7.52639771e-03  3.70349884e-02 -6.46591187e-03  1.18179321e-02\n",
      "  2.50091553e-02 -1.32293701e-02 -1.45282745e-02 -3.11336517e-02\n",
      "  7.16018677e-03 -6.84165955e-03  4.00924683e-03  4.39567566e-02\n",
      " -1.24130249e-02 -1.19476318e-02  6.17218018e-03  3.38840485e-03\n",
      "  2.23388672e-02  1.38320923e-02  2.47192383e-03  1.73950195e-03\n",
      "  2.48146057e-02  2.21633911e-03  2.95286179e-02 -2.47175694e-02\n",
      " -7.43103027e-03 -1.54266357e-02 -2.41470337e-02  5.71441650e-03\n",
      "  9.78851318e-03  8.89272690e-02  1.46827698e-02 -9.57584381e-03\n",
      "  5.75250983e-02  4.61120605e-02 -1.28555298e-02 -2.60114670e-02\n",
      "  8.22448730e-03 -3.11069489e-02  1.82695389e-02 -4.53376770e-03\n",
      " -1.83830261e-02 -6.34288788e-03  1.25007629e-02  1.26152039e-02\n",
      " -2.34451294e-02  1.21765137e-02 -1.59623623e-02 -1.67770386e-02\n",
      "  1.57145858e-02  7.30514526e-04  1.93138123e-02 -4.01420593e-02\n",
      " -3.00483704e-02  2.29663849e-02  3.93009186e-03  1.08604431e-02\n",
      "  1.28402710e-02  4.67014313e-03  3.60946655e-02 -2.34994888e-02\n",
      " -1.80587769e-02 -8.65936279e-04 -1.33018494e-02  2.89230347e-02\n",
      " -2.42156982e-02 -8.81958008e-03  1.60026550e-02  2.72846222e-02\n",
      " -3.43341827e-02 -3.97090912e-02 -3.67965698e-02  2.45475769e-02\n",
      "  7.54547119e-03 -1.64756775e-02  8.00740719e-03 -4.03137207e-02\n",
      " -5.54714203e-02 -3.00292969e-02 -1.42288208e-02  1.14440918e-04\n",
      " -3.18756104e-02 -1.19934082e-02  2.08473206e-02  2.26593018e-03\n",
      "  4.23431396e-04  9.75465775e-03 -2.67162323e-02 -6.40869141e-03\n",
      "  3.99971008e-03 -9.38034058e-03  4.32264805e-03  4.69017029e-03\n",
      "  3.98979187e-02  1.75037384e-02  1.85089111e-02  1.36566162e-03\n",
      "  4.37736511e-03]\n",
      "Updated Intercept: 2.4525108574011747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# split\n",
    "snp_columns = [col for col in data.columns if col.startswith('snp')]\n",
    "\n",
    "# 准备特征和目标变量\n",
    "X = data[snp_columns]\n",
    "y = data['TSLW']\n",
    "\n",
    "# 拆分数据集以进行训练和测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化线性回归模型\n",
    "model1 = LinearRegression()\n",
    "\n",
    "# 使用RFE进行特征选择\n",
    "selector = RFE(model1, n_features_to_select=1, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# 打印特征选择的支持和排名\n",
    "print(\"Support:\", selector.support_)\n",
    "print(\"Ranking:\", selector.ranking_)\n",
    "\n",
    "# 选择特征\n",
    "X_train_selected = X_train[X_train.columns[selector.support_]]\n",
    "X_test_selected = X_test[X_test.columns[selector.support_]]\n",
    "\n",
    "# 拟合最终模型\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train_selected, y_train)\n",
    "\n",
    "# 打印模型的系数和截距\n",
    "print(\"Coefficients:\", model2.coef_)\n",
    "print(\"Intercept:\", model2.intercept_)\n",
    "\n",
    "# 重新准备特征和目标变量，包含新特征\n",
    "X_new = data[snp_columns + cc]\n",
    "y_new = data['TSLW']\n",
    "\n",
    "# 拆分新的训练和测试集\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n",
    "\n",
    "# 重新拟合更新后的模型\n",
    "model3 = LinearRegression()\n",
    "model3.fit(X_train_new, y_train_new)\n",
    "\n",
    "# 打印更新后模型的系数和截距\n",
    "print(\"Updated Coefficients:\", model3.coef_)\n",
    "print(\"Updated Intercept:\", model3.intercept_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSPE: 0.18594212076922859, Rsquare: -0.612479281648346, PearsonE: -0.13363458906111975, PearsonP: PearsonP:0.12089828159756066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr, f\n",
    "\n",
    "# 假设我们已经有训练好的模型和测试数据\n",
    "predictions = model3.predict(X_test_new)\n",
    "\n",
    "# 计算均方预测误差 (MSPE)\n",
    "MSPE = mean_squared_error(y_test_new, predictions)\n",
    "\n",
    "# 计算皮尔逊相关系数\n",
    "PearsonE, PearsonP = pearsonr(y_test_new, predictions)\n",
    "\n",
    "# 计算调整后的R平方\n",
    "n = len(y_test_new)\n",
    "p = len(model3.coef_)\n",
    "Rsquare = model3.score(X_test_new, y_test_new)\n",
    "print(f\"MSPE: {MSPE}, Rsquare: {Rsquare}, PearsonE: {PearsonE}, PearsonP: PearsonP:{PearsonP}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSPE: 0.1919043986999862\n",
      "Pearson Correlation: 0.0021867587434522217\n",
      "Pearson P-value: 0.979842465948152\n",
      "Adjusted R^2: 3.9955308578034545\n",
      "F-statistic: -0.15712766802246703\n",
      "P-value: nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "# 假设data_train1和data_test1是你的训练和测试数据集\n",
    "# 例如:\n",
    "# data_train1 = pd.DataFrame(...)  # 你的训练数据\n",
    "# data_test1 = pd.DataFrame(...)   # 你的测试数据\n",
    "data_train1, data_test1 = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 第一步：初步回归模型\n",
    "X_train = data_train1.drop(columns=['TSLW', \"sample\"])\n",
    "y_train = data_train1['TSLW']\n",
    "selected_features = cc\n",
    "\n",
    "# 第二步：与name.snp和name.otu相关的交互项\n",
    "name_snp = [col for col in selected_features if 'snp' in col]\n",
    "name_otu = [col for col in selected_features if 'OTU' in col]\n",
    "\n",
    "# 添加交互项\n",
    "for snp in name_snp:\n",
    "    for otu in name_otu:\n",
    "        data_train1[snp + '*' + otu] = data_train1[snp] * data_train1[otu]\n",
    "        data_test1[snp + '*' + otu] = data_test1[snp] * data_test1[otu]\n",
    "\n",
    "# 重新选择特征\n",
    "X_train = data_train1.drop(columns=['TSLW', \"sample\"])\n",
    "\n",
    "# 第三步：添加PC相关的特征\n",
    "pc_features = [col for col in data_train1.columns if col.startswith('PC')]\n",
    "X_train = data_train1[cc + pc_features]\n",
    "\n",
    "# 最终模型\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测和评估\n",
    "X_test = data_test1[X_train.columns]\n",
    "y_test = data_test1['TSLW']\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# 计算MSPE\n",
    "mspe = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSPE: {mspe}')\n",
    "\n",
    "# 计算Pearson相关系数\n",
    "pearson_corr, pearson_p = stats.pearsonr(y_test, y_pred)\n",
    "print(f'Pearson Correlation: {pearson_corr}')\n",
    "print(f'Pearson P-value: {pearson_p}')\n",
    "\n",
    "# 计算调整后的R^2\n",
    "r2 = final_model.score(X_test, y_test)\n",
    "n = X_test.shape[0]\n",
    "p = X_test.shape[1]\n",
    "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(f'Adjusted R^2: {adj_r2}')\n",
    "\n",
    "# 计算F统计量和P值\n",
    "f_stat = final_model.score(X_train, y_train) / (1 - final_model.score(X_train, y_train)) * (n - p - 1) / p\n",
    "p_value = 1 - stats.f.cdf(f_stat, p, n - p - 1)\n",
    "print(f'F-statistic: {f_stat}')\n",
    "print(f'P-value: {p_value}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "(136, 210)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}